version: '3.8'

# Common environment variables
x-environment: &common-env
  SUPABASE_URL: https://cqvicgimmzrffvarlokq.supabase.co
  SUPABASE_KEY: ${SUPABASE_KEY:?SUPABASE_KEY is required}

services:
  # Frontend service (development mode)
  frontend:
    build:
      context: ./src/frontend
      dockerfile: Dockerfile.dev
    ports:
      - "5173:5173"
    volumes:
      - ./src/frontend:/app:rw
      - frontend_node_modules:/app/node_modules
    environment:
      - NODE_ENV=development
      - VITE_SUPABASE_URL=https://cqvicgimmzrffvarlokq.supabase.co
      - VITE_SUPABASE_ANON_KEY=${SUPABASE_KEY:?SUPABASE_KEY is required}
      - VITE_BACKEND_URL=http://localhost:8000
      - VITE_SKIP_TS_CHECK=true
      - TZ=Asia/Jerusalem
    depends_on:
      - backend
    networks:
      - afeka_network
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:5173"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 15s
    security_opt:
      - no-new-privileges:true
    restart: unless-stopped
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Backend service (Python development mode)
  backend:
    build:
      context: ./src/backend
      dockerfile: Dockerfile
    ports:
      - "8000:8000"
    volumes:
      - ./src/backend:/app/backend:rw
      - backend_cache:/app/backend/.cache
    environment:
      - PYTHONUNBUFFERED=1
      - SUPABASE_URL=https://cqvicgimmzrffvarlokq.supabase.co
      - SUPABASE_KEY=${SUPABASE_KEY:?SUPABASE_KEY is required}
      - AI_SERVICE_URL=http://ai-service:5000
      - DEBUG=True
      - TZ=Asia/Jerusalem
    depends_on:
      - ai-service
    networks:
      - afeka_network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/api/health"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 10s
    security_opt:
      - no-new-privileges:true
    restart: unless-stopped
    command: uvicorn main:app --host 0.0.0.0 --port 8000 --reload
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # AI service (development mode)
  ai-service:
    build:
      context: ./src/ai
      dockerfile: Dockerfile
    ports:
      - "${AI_SERVICE_PORT:-5000}:5000"
    volumes:
      - ./src/ai:/app/ai:rw
      - ai_cache:/app/ai/.cache
      - ai_models:/app/ai/models:rw
    environment:
      FLASK_APP: app.py
      FLASK_DEBUG: 1
      PYTHONPATH: /app
      DEBUG: "True"
      TZ: Asia/Jerusalem
      GEMINI_API_KEY: ${GEMINI_API_KEY}
    networks:
      - afeka_network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 10s
    security_opt:
      - no-new-privileges:true
    restart: unless-stopped
    command: python app.py
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

networks:
  afeka_network:
    driver: bridge
    ipam:
      driver: default
      config:
        - subnet: 172.29.0.0/16

volumes:
  frontend_node_modules:
    driver: local
  backend_cache:
    driver: local
  ai_cache:
    driver: local 