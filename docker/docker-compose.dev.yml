# Common environment variables
x-environment: &common-env
  SUPABASE_URL: https://cqvicgimmzrffvarlokq.supabase.co
  SUPABASE_KEY: ${SUPABASE_KEY}

# Common resource constraints
x-resources: &default-resources
  cpus: '0.5'
  memory: 512M

services:
  # Frontend service (development mode with hot reload)
  frontend:
    build:
      context: ./src/frontend
      dockerfile: Dockerfile.dev
    ports:
      - "5173:5173"
    deploy:
      resources:
        limits:
          <<: *default-resources
    volumes:
      - ./src/frontend:/app:rw
      - frontend_node_modules:/app/node_modules
    environment:
      - NODE_ENV=development
      - VITE_BACKEND_URL=http://localhost:8000
      - VITE_SUPABASE_URL=https://cqvicgimmzrffvarlokq.supabase.co
      - VITE_SUPABASE_ANON_KEY=${SUPABASE_KEY}
      - VITE_SKIP_TS_CHECK=true
      - CHOKIDAR_USEPOLLING=true
      - WDS_SOCKET_PORT=0
    networks:
      - afeka_network
    depends_on:
      - backend
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:5173/"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 10s
    command: npm run dev -- --host 0.0.0.0

  # Backend service (Python/FastAPI with auto-reload)
  backend:
    build:
      context: ./src/backend
      dockerfile: Dockerfile
    ports:
      - "8000:8000"
    deploy:
      resources:
        limits:
          <<: *default-resources
    volumes:
      - ./src/backend:/app/backend:rw
      - backend_data:/app/backend/data:rw
    environment:
      <<: *common-env
      PYTHONUNBUFFERED: 1
      DEBUG: "True"
      RELOAD: "True"
      AI_SERVICE_URL: http://ai-service:5000
      ALLOWED_ORIGINS: "http://localhost:5173,http://localhost:80,http://localhost,http://frontend:5173"
    networks:
      - afeka_network
    depends_on:
      - ai-service
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/api/health"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 10s
    command: >
      uvicorn main:app --host 0.0.0.0 --port 8000 --reload

  # AI service
  ai-service:
    build:
      context: ./src/ai
      dockerfile: Dockerfile
    ports:
      - "5000:5000"
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 1G
    volumes:
      - ./src/ai:/app/ai:rw
      - ai_models:/app/ai/models:rw
    environment:
      PYTHONUNBUFFERED: 1
      DEBUG: "True"
      GEMINI_API_KEY: ${GEMINI_API_KEY}
    networks:
      - afeka_network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 10s
    command: >
      python app.py

networks:
  afeka_network:
    driver: bridge

volumes:
  frontend_node_modules:
  backend_data:
  ai_models: 