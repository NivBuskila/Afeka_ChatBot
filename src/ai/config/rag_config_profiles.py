#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Configuration profiles for RAG system optimization
=================================================

This file contains different configuration profiles for optimization and A/B testing.
Each profile is tailored for different types of usage or performance.
"""

from dataclasses import dataclass, replace
from typing import Dict, Any
import sys
import os

# ×”×•×¡×¤×ª × ×ª×™×‘ ×œ×˜×¢×™× ×ª config
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, current_dir)

try:
    from rag_config import rag_config, RAGConfig
except ImportError:
    # × ×™×¡×™×•×Ÿ ×™×—×¡×™
    from .rag_config import rag_config, RAGConfig


# Profile 1: Maximum quality (for high accuracy)
def get_high_quality_profile() -> RAGConfig:
    """Profile for maximum quality - high accuracy, lower speed"""
    config = RAGConfig()
    
    # Quality search settings
    config.search.SIMILARITY_THRESHOLD = 0.70  # Higher thresholds
    config.search.HIGH_QUALITY_THRESHOLD = 0.85
    config.search.MAX_CHUNKS_RETRIEVED = 15  # More results
    config.search.MAX_CHUNKS_FOR_CONTEXT = 10  # More context
    config.search.HYBRID_SEMANTIC_WEIGHT = 0.8  # Semantic emphasis
    config.search.HYBRID_KEYWORD_WEIGHT = 0.2
    
    # Smaller chunks for accuracy
    config.chunk.DEFAULT_CHUNK_SIZE = 1500
    config.chunk.DEFAULT_CHUNK_OVERLAP = 300
    config.chunk.TARGET_TOKENS_PER_CHUNK = 300
    
    # More context
    config.context.MAX_CONTEXT_TOKENS = 8000
    config.context.RESERVED_TOKENS_FOR_RESPONSE = 2000
    
    # Quality LLM
    config.llm.TEMPERATURE = 0.05  # Very low for consistency
    config.llm.MAX_OUTPUT_TOKENS = 3000  # Longer responses
    
    return config


# Profile 2: Maximum speed (for performance)
def get_fast_profile() -> RAGConfig:
    """Profile for maximum speed - good performance, reasonable quality"""
    config = RAGConfig()
    
    # Fast search settings
    config.search.SIMILARITY_THRESHOLD = 0.45  # Lower thresholds
    config.search.MAX_CHUNKS_RETRIEVED = 8  # Fewer results
    config.search.MAX_CHUNKS_FOR_CONTEXT = 5  # Less context
    config.search.HYBRID_SEMANTIC_WEIGHT = 0.6  # Balance
    config.search.HYBRID_KEYWORD_WEIGHT = 0.4
    
    # Larger chunks
    config.chunk.DEFAULT_CHUNK_SIZE = 2500
    config.chunk.DEFAULT_CHUNK_OVERLAP = 150
    config.chunk.TARGET_TOKENS_PER_CHUNK = 400
    
    # Less context
    config.context.MAX_CONTEXT_TOKENS = 4000
    config.context.RESERVED_TOKENS_FOR_RESPONSE = 1000
    
    # Fast LLM
    config.llm.TEMPERATURE = 0.2  # Slightly more flexibility
    config.llm.MAX_OUTPUT_TOKENS = 1500  # Shorter responses
    
    # Fast performance
    config.performance.TARGET_SEARCH_TIME_MS = 1000  # 1 second target
    config.performance.TARGET_GENERATION_TIME_MS = 2000  # 2 seconds
    
    return config


# Profile 3: Balanced (improved default)
def get_balanced_profile() -> RAGConfig:
    """Balanced profile - good balance between quality and speed"""
    config = RAGConfig()
    
    # Improved settings based on analysis
    config.search.SIMILARITY_THRESHOLD = 0.4  # â¬‡ï¸ Lowered from 0.55
    config.search.MAX_CHUNKS_RETRIEVED = 20   # â¬†ï¸ Increased from 12
    config.search.MAX_CHUNKS_FOR_CONTEXT = 12 # â¬†ï¸ Increased from 8
    
    # Smaller chunks for better section detection
    config.chunk.DEFAULT_CHUNK_SIZE = 1500   # â¬‡ï¸ Smaller chunks
    config.chunk.DEFAULT_CHUNK_OVERLAP = 300 # â¬†ï¸ More overlap
    
    config.llm.TEMPERATURE = 0.1
    
    return config


# Profile 4: Improved (based on manual analysis)
def get_improved_profile() -> RAGConfig:
    """Profile based on manual testing analysis - optimized for missing sections"""
    config = RAGConfig()
    
    # Very low threshold to catch more sections
    config.search.SIMILARITY_THRESHOLD = 0.3  # Very low to catch all sections
    config.search.HIGH_QUALITY_THRESHOLD = 0.6
    config.search.MAX_CHUNKS_RETRIEVED = 25   # More chunks to analyze
    config.search.MAX_CHUNKS_FOR_CONTEXT = 15 # More context
    
    # Emphasis on semantic search for section numbers
    config.search.HYBRID_SEMANTIC_WEIGHT = 0.9  # Heavy semantic focus
    config.search.HYBRID_KEYWORD_WEIGHT = 0.1   # Less keyword weight
    
    # Small chunks for precise section detection
    config.chunk.DEFAULT_CHUNK_SIZE = 1000   # Very small chunks
    config.chunk.DEFAULT_CHUNK_OVERLAP = 400 # High overlap
    config.chunk.TARGET_TOKENS_PER_CHUNK = 200  # Small token chunks
    
    # More context for complete answers
    config.context.MAX_CONTEXT_TOKENS = 10000
    config.context.RESERVED_TOKENS_FOR_RESPONSE = 3000
    
    # Conservative temperature
    config.llm.TEMPERATURE = 0.05
    config.llm.MAX_OUTPUT_TOKENS = 3000
    
    return config


# Profile 5: Debug and development
def get_debug_profile() -> RAGConfig:
    """Profile for testing and development - detailed logs, low thresholds"""
    config = RAGConfig()
    
    # Low thresholds for testing
    config.search.SIMILARITY_THRESHOLD = 0.30
    config.search.MAX_CHUNKS_RETRIEVED = 20  # Many results for testing
    config.search.MAX_CHUNKS_FOR_CONTEXT = 10
    
    # Detailed logging settings
    config.optimization.ENABLE_DETAILED_LOGGING = True
    config.performance.LOG_SEARCH_ANALYTICS = True
    config.performance.LOG_PERFORMANCE_METRICS = True
    
    # Long timeouts for debugging
    config.search.SEARCH_TIMEOUT_SECONDS = 60
    config.llm.GENERATION_TIMEOUT_SECONDS = 120
    
    return config


# Profile 6: Enhanced Testing - Based on chunking analysis (AGGRESSIVE)
def get_enhanced_testing_profile() -> RAGConfig:
    """
    ×¤×¨×•×¤×™×œ ×ž×©×•×¤×¨ ××’×¨×¡×™×‘×™ ×œ×‘×“×™×§×” ×‘×”×ª×‘×¡×¡ ×¢×œ × ×™×ª×•×— ×ž×ž×¦××™×
    ×ž×ª×§×Ÿ ×‘×¢×™×•×ª chunking strategy ×•×©×™×¤×•×¨ ×–×™×”×•×™ ×¡×¢×™×¤×™× ×§×©×•×¨×™×
    ** UPDATED BASED ON 66.7% FAILURE ANALYSIS **
    """
    config = RAGConfig()
    
    # ðŸš¨ ×¤×¨×ž×˜×¨×™× ××’×¨×¡×™×‘×™×™× ×ž×”× ×™×ª×•×— ×”×—×“×©
    config.search.SIMILARITY_THRESHOLD = 0.15  # ×”× ×ž×›×” ×“×¨×ž×˜×™×ª ×ž-0.2 ×œ-0.15!
    config.search.HIGH_QUALITY_THRESHOLD = 0.5  # ×”× ×ž×›×” ×’× ×›××Ÿ
    config.search.MAX_CHUNKS_RETRIEVED = 40   # ×”×’×“×œ×” ×ž-30 ×œ-40 ×œ×¤×™ ×”×ž×ž×¦××™×
    config.search.MAX_CHUNKS_FOR_CONTEXT = 25 # ×”×’×“×œ×” ×ž-20 ×œ-25 ×œ×˜×™×¤×•×œ ×‘×¡×¢×™×¤×™× ×ž×¤×•×¦×œ×™×
    
    # ðŸ”§ ×©×™×¤×•×¨ ××’×¨×¡×™×‘×™ ×©×œ Chunking Strategy
    config.chunk.DEFAULT_CHUNK_SIZE = 600     # ×§×˜×Ÿ ×™×•×ª×¨ ×ž-800 ×œ×–×™×”×•×™ ×¡×¢×™×¤×™× ×‘×•×“×“×™×
    config.chunk.DEFAULT_CHUNK_OVERLAP = 300  # overlap ×’×‘×•×” ×ž××•×“ ×ž-200 ×œ-300
    config.chunk.TARGET_TOKENS_PER_CHUNK = 120  # ×¤×—×•×ª ×˜×•×§× ×™× ×ž-160 ×œ-120
    
    # ðŸŽ¯ ×©×™×¤×•×¨ ×—×™×¤×•×© semantic ×¢× ×“×’×© ×¢×œ keyword
    config.search.HYBRID_SEMANTIC_WEIGHT = 0.7   # ×”× ×ž×›×” ×ž-0.85 ×œ-0.7
    config.search.HYBRID_KEYWORD_WEIGHT = 0.3    # ×”×’×“×œ×” ×ž-0.15 ×œ-0.3 ×œ×–×™×”×•×™ ×ž×¡×¤×¨×™ ×¡×¢×™×¤×™×
    
    # ðŸ“Š ×”×’×“×œ×ª ×§×•× ×˜×§×¡×˜ ×ž×§×¡×™×ž×œ×™×ª
    config.context.MAX_CONTEXT_TOKENS = 15000    # ×”×’×“×œ×” ×ž-12000 ×œ-15000
    config.context.RESERVED_TOKENS_FOR_RESPONSE = 4000  # ×ž-3000 ×œ-4000
    config.context.CONTEXT_OVERLAP_TOKENS = 200  # ×”×’×“×œ×” ×ž-100 ×œ-200
    
    # ðŸŽ¯ ×”×’×“×¨×•×ª LLM ×ž×•×ª××ž×•×ª ×œ×“×™×•×§ ×ž×§×¡×™×ž×œ×™
    config.llm.TEMPERATURE = 0.02  # ×”× ×ž×›×” ×ž-0.05 ×œ-0.02
    config.llm.MAX_OUTPUT_TOKENS = 5000  # ×”×’×“×œ×” ×ž-4000 ×œ-5000
    
    # ðŸ” ×”×’×“×¨×•×ª ×‘×™×¦×•×¢×™× ×¢× ×–×ž× ×™× ×’×ž×™×©×™× ×™×•×ª×¨
    config.optimization.ENABLE_DETAILED_LOGGING = True
    config.performance.LOG_SEARCH_ANALYTICS = True
    config.performance.LOG_PERFORMANCE_METRICS = True
    config.performance.TARGET_SEARCH_TIME_MS = 5000  # ×”×’×“×œ×” ×ž-3000 ×œ-5000
    config.performance.TARGET_GENERATION_TIME_MS = 8000  # ×”×’×“×œ×” ×ž-5000 ×œ-8000
    
    # â±ï¸ timeouts ×ž×•×ª××ž×™× ×œ×¢×™×‘×•×“ ×ž×•×¨×›×‘ ×ž××•×“
    config.search.SEARCH_TIMEOUT_SECONDS = 120  # ×”×’×“×œ×” ×ž-90 ×œ-120
    config.llm.GENERATION_TIMEOUT_SECONDS = 240  # ×”×’×“×œ×” ×ž-180 ×œ-240
    
    # ðŸŽ›ï¸ ×”×’×“×¨×•×ª × ×•×¡×¤×•×ª ×œ×©×™×¤×•×¨ ×—×™×¤×•×©
    config.search.USE_QUERY_EXPANSION = True  # ×”×•×¡×¤×”
    config.search.ENABLE_FUZZY_MATCHING = True  # ×”×•×¡×¤×”
    config.optimization.ENABLE_CHUNK_RERANKING = True  # ×”×•×¡×¤×”
    
    return config


# Profile 7: Optimized Testing - Based on comprehensive bug analysis
def get_optimized_testing_profile() -> RAGConfig:
    """
    ×¤×¨×•×¤×™×œ ×ž×•×ª×× ×¢×œ ×‘×¡×™×¡ × ×™×ª×•×— ×©×’×™××•×ª ×ž×§×™×£ ×•×‘×“×™×§×” ×™×“× ×™×ª
    ×ž×ª×§×Ÿ ×‘×¢×™×•×ª ×˜×›× ×™×•×ª ×•×ž×©×¤×¨ ×‘×™×¦×•×¢×™× ×œ×§×‘×œ×ª 90%+ ×“×™×•×§
    ** CREATED BASED ON DETAILED 73.3% ANALYSIS **
    """
    config = RAGConfig()
    
    # ðŸŽ¯ ×”×’×“×¨×•×ª ×—×™×¤×•×© ×ž×•×ª××ž×•×ª ×œ× ×™×ª×•×— ×”×—×“×©
    config.search.SIMILARITY_THRESHOLD = 0.12   # × ×ž×•×š ×ž××•×“ ×œ×ª×¤×•×¡ ×’× ×¡×¢×™×¤×™× ×§×©×™×
    config.search.HIGH_QUALITY_THRESHOLD = 0.6   # ×¡×£ ××™×›×•×ª ×¡×‘×™×¨
    config.search.MAX_CHUNKS_RETRIEVED = 25      # ×”×•×¨×“×” ×ž-40 ×œ-25 ×œ×©×™×¤×•×¨ ×ž×”×™×¨×•×ª
    config.search.MAX_CHUNKS_FOR_CONTEXT = 20    # ×”×•×¨×“×” ×ž-25 ×œ-20 ×œ××™×–×•×Ÿ
    
    # ðŸ”§ ×ª×™×§×•×Ÿ chunking ×œ×–×™×”×•×™ ×¡×¢×™×¤×™× ×—×¡×¨×™× (6.2.8, 32.1, 16.1)
    config.chunk.DEFAULT_CHUNK_SIZE = 700        # ×’×“×œ×•×ª ××•×¤×˜×™×ž×œ×™×ª
    config.chunk.DEFAULT_CHUNK_OVERLAP = 350     # overlap ×’×‘×•×” ×ž××•×“ (50%)
    config.chunk.TARGET_TOKENS_PER_CHUNK = 140   # ×˜×•×§× ×™× ×ž×•×ª××ž×™×
    
    # ðŸ“ˆ ×©×™×¤×•×¨ ××™×–×•×Ÿ semantic/keyword ×œ×—×™×¤×•×© ×ž×¡×¤×¨×™ ×¡×¢×™×¤×™×
    config.search.HYBRID_SEMANTIC_WEIGHT = 0.65  # ×¤×—×•×ª semantic
    config.search.HYBRID_KEYWORD_WEIGHT = 0.35   # ×™×•×ª×¨ keyword ×œ×¡×¢×™×¤×™×
    
    # ðŸ“Š ×§×•× ×˜×§×¡×˜ ×ž××•×–×Ÿ ×œ×‘×™×¦×•×¢×™× ×•×’×ž×™×©×•×ª
    config.context.MAX_CONTEXT_TOKENS = 12000    # ×”×•×¨×“×” ×ž-15000 ×œ×©×™×¤×•×¨ ×ž×”×™×¨×•×ª
    config.context.RESERVED_TOKENS_FOR_RESPONSE = 3500  # ×ž××•×–×Ÿ
    config.context.CONTEXT_OVERLAP_TOKENS = 250  # overlap ×’×‘×•×”
    
    # ðŸŽ¯ LLM ×ž××•×–×Ÿ ×œ×“×™×•×§ ×•×ž×”×™×¨×•×ª
    config.llm.TEMPERATURE = 0.03                # ×ž××•×“ × ×ž×•×š ×œ×¢×§×‘×™×•×ª
    config.llm.MAX_OUTPUT_TOKENS = 4000          # ×”×•×¨×“×” ×ž-5000 ×œ×©×™×¤×•×¨ ×ž×”×™×¨×•×ª
    
    # âš¡ ×‘×™×¦×•×¢×™× ×ž×•×ª××ž×™× - ×ž×˜×¨×”: ×ž×ª×—×ª ×œ-3 ×©× ×™×•×ª
    config.performance.TARGET_SEARCH_TIME_MS = 2000   # ×”×•×¨×“×” ×ž-5000
    config.performance.TARGET_GENERATION_TIME_MS = 4000  # ×”×•×¨×“×” ×ž-8000
    
    # ðŸ” ×œ×•×’×™× ×ž×¤×•×¨×˜×™× ×œ× ×™×˜×•×¨ ××™×›×•×ª
    config.optimization.ENABLE_DETAILED_LOGGING = True
    config.performance.LOG_SEARCH_ANALYTICS = True
    config.performance.LOG_PERFORMANCE_METRICS = True
    
    # ðŸš€ ××•×¤×˜×™×ž×™×–×¦×™×•×ª × ×•×¡×¤×•×ª
    config.search.SEARCH_TIMEOUT_SECONDS = 15   # timeout ×ž××•×–×Ÿ
    config.llm.GENERATION_TIMEOUT_SECONDS = 30   # timeout ×ž××•×–×Ÿ
    
    return config


# Profile 8: Maximum Accuracy - No performance compromises
def get_maximum_accuracy_profile() -> RAGConfig:
    """
    ×¤×¨×•×¤×™×œ ×œ×“×™×•×§ ×ž×§×¡×™×ž×œ×™ ×œ×œ× ×”×ª×—×©×‘×•×ª ×‘×ž×”×™×¨×•×ª
    ×ž×‘×•×¡×¡ ×¢×œ ×‘×™×¦×•×¢×™ ×©×™× ×©×œ 96.7% - ×ž×˜×¨×” 98-100%
    ** EXTREME ACCURACY MODE - NO PERFORMANCE LIMITS **
    """
    config = RAGConfig()
    
    # ðŸŽ¯ ×”×’×“×¨×•×ª ×—×™×¤×•×© ××’×¨×¡×™×‘×™×•×ª ×ž×§×¡×™×ž×œ×™×•×ª
    config.search.SIMILARITY_THRESHOLD = 0.8     # ×¡×£ ×’×‘×•×” ×™×•×ª×¨ ×œ××™×›×•×ª ×ž×§×¡×™×ž×œ×™×ª
    config.search.HIGH_QUALITY_THRESHOLD = 0.85  # ×’×‘×•×” ×™×•×ª×¨
    config.search.MAX_CHUNKS_RETRIEVED = 60      # ×ž×§×¡×™×ž×•× ×¦'×× ×§×™× ××¤×©×¨×™
    config.search.MAX_CHUNKS_FOR_CONTEXT = 50    # ×ž×§×¡×™×ž×•× ×‘×§×•× ×˜×§×¡×˜
    
    # ðŸ”§ Chunking ××•×¤×˜×™×ž×œ×™ ×œ×›×™×¡×•×™ ×ž×§×¡×™×ž×œ×™
    config.chunk.DEFAULT_CHUNK_SIZE = 800        # ×’×“×œ×•×ª ×ž××•×–× ×ª
    config.chunk.DEFAULT_CHUNK_OVERLAP = 400     # 50% overlap ×ž×§×¡×™×ž×œ×™
    config.chunk.TARGET_TOKENS_PER_CHUNK = 160   # ×˜×•×§× ×™× ×ž×¤×•×¨×˜×™×
    
    # ðŸ“ˆ ××™×–×•×Ÿ ×œ×˜×•×‘×ª semantic (×–×™×”×•×™ ×ž×•×©×’×™× ×¢×ž×•×§)
    config.search.HYBRID_SEMANTIC_WEIGHT = 0.75  # ×“×’×© ×¢×œ semantic
    config.search.HYBRID_KEYWORD_WEIGHT = 0.25   # keyword ×ž×©×œ×™×
    
    # ðŸ“Š ×§×•× ×˜×§×¡×˜ ×ž×§×¡×™×ž×œ×™ - ××¤×¡ ×¤×©×¨×•×ª
    config.context.MAX_CONTEXT_TOKENS = 20000    # ×ž×§×¡×™×ž×•× ×’×‘×•×”
    config.context.RESERVED_TOKENS_FOR_RESPONSE = 6000  # ×ª×©×•×‘×•×ª ×ž×¤×•×¨×˜×•×ª
    config.context.CONTEXT_OVERLAP_TOKENS = 500  # overlap ×’×‘×•×” ×ž××•×“
    
    # ðŸŽ¯ LLM ×œ×“×™×•×§ ×ž×•×—×œ×˜
    config.llm.TEMPERATURE = 0.01                # ×›×ž×¢×˜ ×“×˜×¨×ž×™× ×™×¡×˜×™ ×œ×—×œ×•×˜×™×Ÿ
    config.llm.MAX_OUTPUT_TOKENS = 6000          # ×ª×©×•×‘×•×ª ×ž×§×™×¤×•×ª
    config.llm.TOP_P = 0.9                       # ×“×™×•×§ ×’×‘×•×”
    
    # âš¡ ×‘×™×¦×•×¢×™× - ×ž×”×™×¨×•×ª ×œ× ×¨×œ×•×•× ×˜×™×ª
    config.performance.TARGET_SEARCH_TIME_MS = 10000   # 10 ×©× ×™×•×ª - ×œ× ×ž×©× ×”
    config.performance.TARGET_GENERATION_TIME_MS = 15000  # 15 ×©× ×™×•×ª - ×œ× ×ž×©× ×”
    
    # ðŸ” ×›×œ ×”××•×¤×˜×™×ž×™×–×¦×™×•×ª ×”××¤×©×¨×™×•×ª
    config.optimization.ENABLE_DETAILED_LOGGING = True
    config.performance.LOG_SEARCH_ANALYTICS = True
    config.performance.LOG_PERFORMANCE_METRICS = True
    config.optimization.ENABLE_CHUNK_RERANKING = True
    
    # ðŸš€ timeouts ×’×‘×•×”×™× ×œ×¢×™×‘×•×“ ×ž×•×¨×›×‘
    config.search.SEARCH_TIMEOUT_SECONDS = 300   # 5 ×“×§×•×ª
    config.llm.GENERATION_TIMEOUT_SECONDS = 600  # 10 ×“×§×•×ª
    
    # ðŸŽ›ï¸ ×”×’×“×¨×•×ª ×ž×ª×§×“×ž×•×ª ×œ×“×™×•×§ ×ž×§×¡×™×ž×œ×™
    config.search.USE_QUERY_EXPANSION = True     # ×”×¨×—×‘×ª ×—×™×¤×•×©
    config.search.ENABLE_FUZZY_MATCHING = True   # ×”×ª××ž×” ×ž×¢×•×¨×¤×œ×ª
    config.context.ENABLE_CONTEXT_RERANKING = True  # ×“×™×¨×•×’ ×ž×—×“×© ×©×œ ×§×•× ×˜×§×¡×˜
    
    return config


# Dictionary of all profiles
PROFILES = {
    "high_quality": get_high_quality_profile,
    "fast": get_fast_profile,
    "balanced": get_balanced_profile,
    "improved": get_improved_profile,
    "debug": get_debug_profile,
    "enhanced_testing": get_enhanced_testing_profile,
    "optimized_testing": get_optimized_testing_profile,
    "maximum_accuracy": get_maximum_accuracy_profile,
}


def get_profile(profile_name: str) -> RAGConfig:
    """Returns profile by name"""
    if profile_name not in PROFILES:
        available = ", ".join(PROFILES.keys())
        raise ValueError(f"Profile '{profile_name}' does not exist. Available profiles: {available}")
    
    return PROFILES[profile_name]()


def list_profiles() -> Dict[str, str]:
    """Returns list of profiles with descriptions"""
    return {
        "high_quality": "Maximum quality - high accuracy, lower speed",
        "fast": "Maximum speed - good performance, reasonable quality",
        "balanced": "Balanced - improved settings based on analysis",
        "improved": "Optimized for missing sections - very low threshold, small chunks",
        "debug": "Debug and development - detailed logs, low thresholds",
        "enhanced_testing": "Enhanced Testing (AGGRESSIVE) - Based on 66.7% failure analysis",
        "optimized_testing": "Optimized Testing - Balanced performance & accuracy (73.3% analysis)",
        "maximum_accuracy": "Maximum Accuracy - No performance limits (Target: 98-100%)",
    }


def compare_profiles(profile1_name: str, profile2_name: str) -> Dict[str, Any]:
    """Compares two profiles"""
    profile1 = get_profile(profile1_name)
    profile2 = get_profile(profile2_name)
    
    comparison = {
        "similarity_threshold": {
            profile1_name: profile1.search.SIMILARITY_THRESHOLD,
            profile2_name: profile2.search.SIMILARITY_THRESHOLD
        },
        "max_chunks": {
            profile1_name: profile1.search.MAX_CHUNKS_RETRIEVED,
            profile2_name: profile2.search.MAX_CHUNKS_RETRIEVED
        },
        "context_tokens": {
            profile1_name: profile1.context.MAX_CONTEXT_TOKENS,
            profile2_name: profile2.context.MAX_CONTEXT_TOKENS
        },
        "temperature": {
            profile1_name: profile1.llm.TEMPERATURE,
            profile2_name: profile2.llm.TEMPERATURE
        },
        "semantic_weight": {
            profile1_name: profile1.search.HYBRID_SEMANTIC_WEIGHT,
            profile2_name: profile2.search.HYBRID_SEMANTIC_WEIGHT
        }
    }
    
    return comparison


if __name__ == "__main__":
    print("ðŸ”§ RAG Configuration Profiles")
    print("=" * 50)
    
    # Display all profiles
    profiles_info = list_profiles()
    for name, description in profiles_info.items():
        print(f"\nðŸ“‹ {name.upper()}:")
        print(f"   {description}")
        
        # Display key settings
        profile = get_profile(name)
        print(f"   ðŸ“Š Key settings:")
        print(f"      Similarity threshold: {profile.search.SIMILARITY_THRESHOLD}")
        print(f"      Max chunks: {profile.search.MAX_CHUNKS_RETRIEVED}")
        print(f"      Context tokens: {profile.context.MAX_CONTEXT_TOKENS}")
        print(f"      Temperature: {profile.llm.TEMPERATURE}")
        print(f"      Semantic/Keyword weights: {profile.search.HYBRID_SEMANTIC_WEIGHT}/{profile.search.HYBRID_KEYWORD_WEIGHT}")
    
    print(f"\nðŸ“ˆ Comparison: fast vs high_quality")
    comparison = compare_profiles("fast", "high_quality")
    for metric, values in comparison.items():
        print(f"   {metric}: {values}")
