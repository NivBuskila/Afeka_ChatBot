#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Configuration profiles for RAG system optimization
=================================================

This file contains different configuration profiles for optimization and A/B testing.
Each profile is tailored for different types of usage or performance.
"""

from dataclasses import dataclass, replace
from typing import Dict, Any, List
import sys
import os
import json
from pathlib import Path

# ×”×•×¡×¤×ª × ×ª×™×‘ ×œ×˜×¢×™× ×ª config
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, current_dir)

try:
    from rag_config import rag_config, RAGConfig
except ImportError:
    # × ×™×¡×™×•×Ÿ ×™×—×¡×™
    from .rag_config import rag_config, RAGConfig

# × ×ª×™×‘ ×œ×§×•×‘×¥ ×”×¤×¨×•×¤×™×œ×™× ×”×“×™× ×ž×™×™×
DYNAMIC_PROFILES_FILE = Path(current_dir) / "dynamic_profiles.json"

# Global dictionary to store descriptions for dynamically created profiles
DYNAMIC_PROFILE_DESCRIPTIONS = {}

def load_dynamic_profiles() -> Dict[str, Any]:
    """×˜×•×¢×Ÿ ×¤×¨×•×¤×™×œ×™× ×“×™× ×ž×™×™× ×ž×§×•×‘×¥ JSON"""
    if not DYNAMIC_PROFILES_FILE.exists():
        return {}
    
    try:
        with open(DYNAMIC_PROFILES_FILE, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        print(f"Error loading dynamic profiles: {e}")
        return {}

def save_dynamic_profiles(profiles_data: Dict[str, Any]) -> None:
    """×©×•×ž×¨ ×¤×¨×•×¤×™×œ×™× ×“×™× ×ž×™×™× ×œ×§×•×‘×¥ JSON"""
    try:
        with open(DYNAMIC_PROFILES_FILE, 'w', encoding='utf-8') as f:
            json.dump(profiles_data, f, ensure_ascii=False, indent=2)
    except Exception as e:
        print(f"Error saving dynamic profiles: {e}")

def load_hidden_profiles() -> List[str]:
    """×˜×•×¢×Ÿ ×¨×©×™×ž×ª ×¤×¨×•×¤×™×œ×™× ×ž×•×‘× ×™× ×ž×•×¡×ª×¨×™×"""
    hidden_file = Path(current_dir) / "hidden_profiles.json"
    try:
        if hidden_file.exists():
            with open(hidden_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                return data.get('hidden_profiles', [])
        return []
    except Exception as e:
        print(f"Error loading hidden profiles: {e}")
        return []

def save_hidden_profiles(hidden_list: List[str]) -> None:
    """×©×•×ž×¨ ×¨×©×™×ž×ª ×¤×¨×•×¤×™×œ×™× ×ž×•×‘× ×™× ×ž×•×¡×ª×¨×™×"""
    hidden_file = Path(current_dir) / "hidden_profiles.json"
    try:
        data = {'hidden_profiles': hidden_list}
        with open(hidden_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
    except Exception as e:
        print(f"Error saving hidden profiles: {e}")

def hide_builtin_profile(profile_id: str) -> bool:
    """×ž×¡×ª×™×¨ ×¤×¨×•×¤×™×œ ×ž×•×‘× ×” ×ž×”×¨×©×™×ž×” ×”×–×ž×™× ×”"""
    try:
        # ×•×•×“× ×©×–×” ×¤×¨×•×¤×™×œ ×ž×•×‘× ×”
        built_in_profiles = {"high_quality", "fast", "balanced", "improved", "debug", 
                            "enhanced_testing", "optimized_testing", "maximum_accuracy"}
        
        if profile_id not in built_in_profiles:
            return False  # ×œ× ×¤×¨×•×¤×™×œ ×ž×•×‘× ×”
        
        # ×˜×¢×Ÿ ×¨×©×™×ž×ª ×ž×•×¡×ª×¨×™× × ×•×›×—×™×ª
        hidden_profiles = load_hidden_profiles()
        
        # ×”×•×¡×£ ×œ×¨×©×™×ž×” ×× ×œ× ×§×™×™×
        if profile_id not in hidden_profiles:
            hidden_profiles.append(profile_id)
            save_hidden_profiles(hidden_profiles)
        
        return True
    except Exception as e:
        print(f"Error hiding built-in profile {profile_id}: {e}")
        return False

def restore_builtin_profile(profile_id: str) -> bool:
    """×ž×©×—×–×¨ ×¤×¨×•×¤×™×œ ×ž×•×‘× ×” ×ž×•×¡×ª×¨"""
    try:
        hidden_profiles = load_hidden_profiles()
        
        if profile_id in hidden_profiles:
            hidden_profiles.remove(profile_id)
            save_hidden_profiles(hidden_profiles)
            return True
        
        return False  # ×œ× ×”×™×” ×ž×•×¡×ª×¨
    except Exception as e:
        print(f"Error restoring built-in profile {profile_id}: {e}")
        return False

def create_profile_from_data(profile_data: Dict[str, Any]) -> RAGConfig:
    """×™×•×¦×¨ RAGConfig ×ž× ×ª×•× ×™ ×¤×¨×•×¤×™×œ ×©×ž×•×¨×™×"""
    config = RAGConfig()
    
    # Apply configuration from saved data
    config_data = profile_data.get('config', {})
    
    config.search.SIMILARITY_THRESHOLD = float(config_data.get("similarityThreshold", 0.4))
    config.search.MAX_CHUNKS_RETRIEVED = int(config_data.get("maxChunks", 15))
    config.search.MAX_CHUNKS_FOR_CONTEXT = int(config_data.get("maxChunks", 15))
    config.llm.TEMPERATURE = float(config_data.get("temperature", 0.1))
    config.llm.MODEL_NAME = config_data.get("modelName", "gemini-2.0-flash")
    
    # Optional advanced configurations
    if "chunkSize" in config_data:
        config.chunk.DEFAULT_CHUNK_SIZE = int(config_data["chunkSize"])
    if "chunkOverlap" in config_data:
        config.chunk.DEFAULT_CHUNK_OVERLAP = int(config_data["chunkOverlap"])
    if "maxContextTokens" in config_data:
        config.context.MAX_CONTEXT_TOKENS = int(config_data["maxContextTokens"])
    if "targetTokensPerChunk" in config_data:
        config.chunk.TARGET_TOKENS_PER_CHUNK = int(config_data["targetTokensPerChunk"])
    if "hybridSemanticWeight" in config_data:
        config.search.HYBRID_SEMANTIC_WEIGHT = float(config_data["hybridSemanticWeight"])
    if "hybridKeywordWeight" in config_data:
        config.search.HYBRID_KEYWORD_WEIGHT = float(config_data["hybridKeywordWeight"])
    
    return config

# ×˜×¢×Ÿ ×¤×¨×•×¤×™×œ×™× ×“×™× ×ž×™×™× ×‘×¢×ª ×”××ª×—×•×œ
dynamic_profiles_data = load_dynamic_profiles()

# Profile 1: Maximum quality (for high accuracy)
def get_high_quality_profile() -> RAGConfig:
    """Profile for maximum quality - high accuracy, lower speed"""
    config = RAGConfig()
    
    # Quality search settings
    config.search.SIMILARITY_THRESHOLD = 0.70  # Higher thresholds
    config.search.HIGH_QUALITY_THRESHOLD = 0.85
    config.search.MAX_CHUNKS_RETRIEVED = 15  # More results
    config.search.MAX_CHUNKS_FOR_CONTEXT = 10  # More context
    config.search.HYBRID_SEMANTIC_WEIGHT = 0.8  # Semantic emphasis
    config.search.HYBRID_KEYWORD_WEIGHT = 0.2
    
    # Smaller chunks for accuracy
    config.chunk.DEFAULT_CHUNK_SIZE = 1500
    config.chunk.DEFAULT_CHUNK_OVERLAP = 300
    config.chunk.TARGET_TOKENS_PER_CHUNK = 300
    
    # More context
    config.context.MAX_CONTEXT_TOKENS = 8000
    config.context.RESERVED_TOKENS_FOR_RESPONSE = 2000
    
    # Quality LLM
    config.llm.TEMPERATURE = 0.05  # Very low for consistency
    config.llm.MAX_OUTPUT_TOKENS = 3000  # Longer responses
    
    return config


# Profile 2: Maximum speed (for performance)
def get_fast_profile() -> RAGConfig:
    """Profile for maximum speed - good performance, reasonable quality"""
    config = RAGConfig()
    
    # Fast search settings
    config.search.SIMILARITY_THRESHOLD = 0.45  # Lower thresholds
    config.search.MAX_CHUNKS_RETRIEVED = 8  # Fewer results
    config.search.MAX_CHUNKS_FOR_CONTEXT = 5  # Less context
    config.search.HYBRID_SEMANTIC_WEIGHT = 0.6  # Balance
    config.search.HYBRID_KEYWORD_WEIGHT = 0.4
    
    # Larger chunks
    config.chunk.DEFAULT_CHUNK_SIZE = 2500
    config.chunk.DEFAULT_CHUNK_OVERLAP = 150
    config.chunk.TARGET_TOKENS_PER_CHUNK = 400
    
    # Less context
    config.context.MAX_CONTEXT_TOKENS = 4000
    config.context.RESERVED_TOKENS_FOR_RESPONSE = 1000
    
    # Fast LLM
    config.llm.TEMPERATURE = 0.2  # Slightly more flexibility
    config.llm.MAX_OUTPUT_TOKENS = 1500  # Shorter responses
    
    # Fast performance
    config.performance.TARGET_SEARCH_TIME_MS = 1000  # 1 second target
    config.performance.TARGET_GENERATION_TIME_MS = 2000  # 2 seconds
    
    return config


# Profile 3: Balanced (improved default)
def get_balanced_profile() -> RAGConfig:
    """Balanced profile - good balance between quality and speed"""
    config = RAGConfig()
    
    # Improved settings based on analysis
    config.search.SIMILARITY_THRESHOLD = 0.4  # â¬‡ï¸ Lowered from 0.55
    config.search.MAX_CHUNKS_RETRIEVED = 20   # â¬†ï¸ Increased from 12
    config.search.MAX_CHUNKS_FOR_CONTEXT = 12 # â¬†ï¸ Increased from 8
    
    # Smaller chunks for better section detection
    config.chunk.DEFAULT_CHUNK_SIZE = 1500   # â¬‡ï¸ Smaller chunks
    config.chunk.DEFAULT_CHUNK_OVERLAP = 300 # â¬†ï¸ More overlap
    
    config.llm.TEMPERATURE = 0.1
    
    return config


# Profile 4: Improved (based on manual analysis)
def get_improved_profile() -> RAGConfig:
    """Profile based on manual testing analysis - optimized for missing sections"""
    config = RAGConfig()
    
    # Very low threshold to catch more sections
    config.search.SIMILARITY_THRESHOLD = 0.3  # Very low to catch all sections
    config.search.HIGH_QUALITY_THRESHOLD = 0.6
    config.search.MAX_CHUNKS_RETRIEVED = 25   # More chunks to analyze
    config.search.MAX_CHUNKS_FOR_CONTEXT = 15 # More context
    
    # Emphasis on semantic search for section numbers
    config.search.HYBRID_SEMANTIC_WEIGHT = 0.9  # Heavy semantic focus
    config.search.HYBRID_KEYWORD_WEIGHT = 0.1   # Less keyword weight
    
    # Small chunks for precise section detection
    config.chunk.DEFAULT_CHUNK_SIZE = 1000   # Very small chunks
    config.chunk.DEFAULT_CHUNK_OVERLAP = 400 # High overlap
    config.chunk.TARGET_TOKENS_PER_CHUNK = 200  # Small token chunks
    
    # More context for complete answers
    config.context.MAX_CONTEXT_TOKENS = 10000
    config.context.RESERVED_TOKENS_FOR_RESPONSE = 3000
    
    # Conservative temperature
    config.llm.TEMPERATURE = 0.05
    config.llm.MAX_OUTPUT_TOKENS = 3000
    
    return config


# Profile 5: Debug and development
def get_debug_profile() -> RAGConfig:
    """Profile for testing and development - detailed logs, low thresholds"""
    config = RAGConfig()
    
    # Low thresholds for testing
    config.search.SIMILARITY_THRESHOLD = 0.30
    config.search.MAX_CHUNKS_RETRIEVED = 20  # Many results for testing
    config.search.MAX_CHUNKS_FOR_CONTEXT = 10
    
    # Detailed logging settings
    config.optimization.ENABLE_DETAILED_LOGGING = True
    config.performance.LOG_SEARCH_ANALYTICS = True
    config.performance.LOG_PERFORMANCE_METRICS = True
    
    # Long timeouts for debugging
    config.search.SEARCH_TIMEOUT_SECONDS = 60
    config.llm.GENERATION_TIMEOUT_SECONDS = 120
    
    return config


# Profile 6: Enhanced Testing - Based on chunking analysis (AGGRESSIVE)
def get_enhanced_testing_profile() -> RAGConfig:
    """
    ×¤×¨×•×¤×™×œ ×ž×©×•×¤×¨ ××’×¨×¡×™×‘×™ ×œ×‘×“×™×§×” ×‘×”×ª×‘×¡×¡ ×¢×œ × ×™×ª×•×— ×ž×ž×¦××™×
    ×ž×ª×§×Ÿ ×‘×¢×™×•×ª chunking strategy ×•×©×™×¤×•×¨ ×–×™×”×•×™ ×¡×¢×™×¤×™× ×§×©×•×¨×™×
    ** UPDATED BASED ON 66.7% FAILURE ANALYSIS **
    """
    config = RAGConfig()
    
    # ðŸš¨ ×¤×¨×ž×˜×¨×™× ××’×¨×¡×™×‘×™×™× ×ž×”× ×™×ª×•×— ×”×—×“×©
    config.search.SIMILARITY_THRESHOLD = 0.15  # ×”× ×ž×›×” ×“×¨×ž×˜×™×ª ×ž-0.2 ×œ-0.15!
    config.search.HIGH_QUALITY_THRESHOLD = 0.5  # ×”× ×ž×›×” ×’× ×›××Ÿ
    config.search.MAX_CHUNKS_RETRIEVED = 40   # ×”×’×“×œ×” ×ž-30 ×œ-40 ×œ×¤×™ ×”×ž×ž×¦××™×
    config.search.MAX_CHUNKS_FOR_CONTEXT = 25 # ×”×’×“×œ×” ×ž-20 ×œ-25 ×œ×˜×™×¤×•×œ ×‘×¡×¢×™×¤×™× ×ž×¤×•×¦×œ×™×
    
    # ðŸ”§ ×©×™×¤×•×¨ ××’×¨×¡×™×‘×™ ×©×œ Chunking Strategy
    config.chunk.DEFAULT_CHUNK_SIZE = 600     # ×§×˜×Ÿ ×™×•×ª×¨ ×ž-800 ×œ×–×™×”×•×™ ×¡×¢×™×¤×™× ×‘×•×“×“×™×
    config.chunk.DEFAULT_CHUNK_OVERLAP = 300  # overlap ×’×‘×•×” ×ž××•×“ ×ž-200 ×œ-300
    config.chunk.TARGET_TOKENS_PER_CHUNK = 120  # ×¤×—×•×ª ×˜×•×§× ×™× ×ž-160 ×œ-120
    
    # ðŸŽ¯ ×©×™×¤×•×¨ ×—×™×¤×•×© semantic ×¢× ×“×’×© ×¢×œ keyword
    config.search.HYBRID_SEMANTIC_WEIGHT = 0.7   # ×”× ×ž×›×” ×ž-0.85 ×œ-0.7
    config.search.HYBRID_KEYWORD_WEIGHT = 0.3    # ×”×’×“×œ×” ×ž-0.15 ×œ-0.3 ×œ×–×™×”×•×™ ×ž×¡×¤×¨×™ ×¡×¢×™×¤×™×
    
    # ðŸ“Š ×”×’×“×œ×ª ×§×•× ×˜×§×¡×˜ ×ž×§×¡×™×ž×œ×™×ª
    config.context.MAX_CONTEXT_TOKENS = 15000    # ×”×’×“×œ×” ×ž-12000 ×œ-15000
    config.context.RESERVED_TOKENS_FOR_RESPONSE = 4000  # ×ž-3000 ×œ-4000
    config.context.CONTEXT_OVERLAP_TOKENS = 200  # ×”×’×“×œ×” ×ž-100 ×œ-200
    
    # ðŸŽ¯ ×”×’×“×¨×•×ª LLM ×ž×•×ª××ž×•×ª ×œ×“×™×•×§ ×ž×§×¡×™×ž×œ×™
    config.llm.TEMPERATURE = 0.02  # ×”× ×ž×›×” ×ž-0.05 ×œ-0.02
    config.llm.MAX_OUTPUT_TOKENS = 5000  # ×”×’×“×œ×” ×ž-4000 ×œ-5000
    
    # ðŸ” ×”×’×“×¨×•×ª ×‘×™×¦×•×¢×™× ×¢× ×–×ž× ×™× ×’×ž×™×©×™× ×™×•×ª×¨
    config.optimization.ENABLE_DETAILED_LOGGING = True
    config.performance.LOG_SEARCH_ANALYTICS = True
    config.performance.LOG_PERFORMANCE_METRICS = True
    config.performance.TARGET_SEARCH_TIME_MS = 5000  # ×”×’×“×œ×” ×ž-3000 ×œ-5000
    config.performance.TARGET_GENERATION_TIME_MS = 8000  # ×”×’×“×œ×” ×ž-5000 ×œ-8000
    
    # â±ï¸ timeouts ×ž×•×ª××ž×™× ×œ×¢×™×‘×•×“ ×ž×•×¨×›×‘ ×ž××•×“
    config.search.SEARCH_TIMEOUT_SECONDS = 120  # ×”×’×“×œ×” ×ž-90 ×œ-120
    config.llm.GENERATION_TIMEOUT_SECONDS = 240  # ×”×’×“×œ×” ×ž-180 ×œ-240
    
    # ðŸŽ›ï¸ ×”×’×“×¨×•×ª × ×•×¡×¤×•×ª ×œ×©×™×¤×•×¨ ×—×™×¤×•×©
    config.search.USE_QUERY_EXPANSION = True  # ×”×•×¡×¤×”
    config.search.ENABLE_FUZZY_MATCHING = True  # ×”×•×¡×¤×”
    config.optimization.ENABLE_CHUNK_RERANKING = True  # ×”×•×¡×¤×”
    
    return config


# Profile 7: Optimized Testing - Based on comprehensive bug analysis
def get_optimized_testing_profile() -> RAGConfig:
    """
    ×¤×¨×•×¤×™×œ ×ž×•×ª×× ×¢×œ ×‘×¡×™×¡ × ×™×ª×•×— ×©×’×™××•×ª ×ž×§×™×£ ×•×‘×“×™×§×” ×™×“× ×™×ª
    ×ž×ª×§×Ÿ ×‘×¢×™×•×ª ×˜×›× ×™×•×ª ×•×ž×©×¤×¨ ×‘×™×¦×•×¢×™× ×œ×§×‘×œ×ª 90%+ ×“×™×•×§
    ** CREATED BASED ON DETAILED 73.3% ANALYSIS **
    """
    config = RAGConfig()
    
    # ðŸŽ¯ ×”×’×“×¨×•×ª ×—×™×¤×•×© ×ž×•×ª××ž×•×ª ×œ× ×™×ª×•×— ×”×—×“×©
    config.search.SIMILARITY_THRESHOLD = 0.12   # × ×ž×•×š ×ž××•×“ ×œ×ª×¤×•×¡ ×’× ×¡×¢×™×¤×™× ×§×©×™×
    config.search.HIGH_QUALITY_THRESHOLD = 0.6   # ×¡×£ ××™×›×•×ª ×¡×‘×™×¨
    config.search.MAX_CHUNKS_RETRIEVED = 25      # ×”×•×¨×“×” ×ž-40 ×œ-25 ×œ×©×™×¤×•×¨ ×ž×”×™×¨×•×ª
    config.search.MAX_CHUNKS_FOR_CONTEXT = 20    # ×”×•×¨×“×” ×ž-25 ×œ-20 ×œ××™×–×•×Ÿ
    
    # ðŸ”§ ×ª×™×§×•×Ÿ chunking ×œ×–×™×”×•×™ ×¡×¢×™×¤×™× ×—×¡×¨×™× (6.2.8, 32.1, 16.1)
    config.chunk.DEFAULT_CHUNK_SIZE = 700        # ×’×“×œ×•×ª ××•×¤×˜×™×ž×œ×™×ª
    config.chunk.DEFAULT_CHUNK_OVERLAP = 350     # overlap ×’×‘×•×” ×ž××•×“ (50%)
    config.chunk.TARGET_TOKENS_PER_CHUNK = 140   # ×˜×•×§× ×™× ×ž×•×ª××ž×™×
    
    # ðŸ“ˆ ×©×™×¤×•×¨ ××™×–×•×Ÿ semantic/keyword ×œ×—×™×¤×•×© ×ž×¡×¤×¨×™ ×¡×¢×™×¤×™×
    config.search.HYBRID_SEMANTIC_WEIGHT = 0.65  # ×¤×—×•×ª semantic
    config.search.HYBRID_KEYWORD_WEIGHT = 0.35   # ×™×•×ª×¨ keyword ×œ×¡×¢×™×¤×™×
    
    # ðŸ“Š ×§×•× ×˜×§×¡×˜ ×ž××•×–×Ÿ ×œ×‘×™×¦×•×¢×™× ×•×’×ž×™×©×•×ª
    config.context.MAX_CONTEXT_TOKENS = 12000    # ×”×•×¨×“×” ×ž-15000 ×œ×©×™×¤×•×¨ ×ž×”×™×¨×•×ª
    config.context.RESERVED_TOKENS_FOR_RESPONSE = 3500  # ×ž××•×–×Ÿ
    config.context.CONTEXT_OVERLAP_TOKENS = 250  # overlap ×’×‘×•×”
    
    # ðŸŽ¯ LLM ×ž××•×–×Ÿ ×œ×“×™×•×§ ×•×ž×”×™×¨×•×ª
    config.llm.TEMPERATURE = 0.03                # ×ž××•×“ × ×ž×•×š ×œ×¢×§×‘×™×•×ª
    config.llm.MAX_OUTPUT_TOKENS = 4000          # ×”×•×¨×“×” ×ž-5000 ×œ×©×™×¤×•×¨ ×ž×”×™×¨×•×ª
    
    # âš¡ ×‘×™×¦×•×¢×™× ×ž×•×ª××ž×™× - ×ž×˜×¨×”: ×ž×ª×—×ª ×œ-3 ×©× ×™×•×ª
    config.performance.TARGET_SEARCH_TIME_MS = 2000   # ×”×•×¨×“×” ×ž-5000
    config.performance.TARGET_GENERATION_TIME_MS = 4000  # ×”×•×¨×“×” ×ž-8000
    
    # ðŸ” ×œ×•×’×™× ×ž×¤×•×¨×˜×™× ×œ× ×™×˜×•×¨ ××™×›×•×ª
    config.optimization.ENABLE_DETAILED_LOGGING = True
    config.performance.LOG_SEARCH_ANALYTICS = True
    config.performance.LOG_PERFORMANCE_METRICS = True
    
    # ðŸš€ ××•×¤×˜×™×ž×™×–×¦×™×•×ª × ×•×¡×¤×•×ª
    config.search.SEARCH_TIMEOUT_SECONDS = 15   # timeout ×ž××•×–×Ÿ
    config.llm.GENERATION_TIMEOUT_SECONDS = 30   # timeout ×ž××•×–×Ÿ
    
    return config


# Profile 8: Maximum Accuracy - No performance compromises
def get_maximum_accuracy_profile() -> RAGConfig:
    """
    ×¤×¨×•×¤×™×œ ×œ×“×™×•×§ ×ž×§×¡×™×ž×œ×™ ×œ×œ× ×”×ª×—×©×‘×•×ª ×‘×ž×”×™×¨×•×ª
    ×ž×‘×•×¡×¡ ×¢×œ ×‘×™×¦×•×¢×™ ×©×™× ×©×œ 96.7% - ×ž×˜×¨×” 98-100%
    ** EXTREME ACCURACY MODE - NO PERFORMANCE LIMITS **
    """
    config = RAGConfig()
    
    # ðŸŽ¯ ×”×’×“×¨×•×ª ×—×™×¤×•×© ××’×¨×¡×™×‘×™×•×ª ×ž×§×¡×™×ž×œ×™×•×ª
    config.search.SIMILARITY_THRESHOLD = 0.08     # ×¡×£ ×’×‘×•×” ×™×•×ª×¨ ×œ××™×›×•×ª ×ž×§×¡×™×ž×œ×™×ª
    config.search.HIGH_QUALITY_THRESHOLD = 0.85  # ×’×‘×•×” ×™×•×ª×¨
    config.search.MAX_CHUNKS_RETRIEVED = 60      # ×ž×§×¡×™×ž×•× ×¦'×× ×§×™× ××¤×©×¨×™
    config.search.MAX_CHUNKS_FOR_CONTEXT = 50    # ×ž×§×¡×™×ž×•× ×‘×§×•× ×˜×§×¡×˜
    
    # ðŸ”§ Chunking ××•×¤×˜×™×ž×œ×™ ×œ×›×™×¡×•×™ ×ž×§×¡×™×ž×œ×™
    config.chunk.DEFAULT_CHUNK_SIZE = 800        # ×’×“×œ×•×ª ×ž××•×–× ×ª
    config.chunk.DEFAULT_CHUNK_OVERLAP = 400     # 50% overlap ×ž×§×¡×™×ž×œ×™
    config.chunk.TARGET_TOKENS_PER_CHUNK = 160   # ×˜×•×§× ×™× ×ž×¤×•×¨×˜×™×
    
    # ðŸ“ˆ ××™×–×•×Ÿ ×œ×˜×•×‘×ª semantic (×–×™×”×•×™ ×ž×•×©×’×™× ×¢×ž×•×§)
    config.search.HYBRID_SEMANTIC_WEIGHT = 0.75  # ×“×’×© ×¢×œ semantic
    config.search.HYBRID_KEYWORD_WEIGHT = 0.25   # keyword ×ž×©×œ×™×
    
    # ðŸ“Š ×§×•× ×˜×§×¡×˜ ×ž×§×¡×™×ž×œ×™ - ××¤×¡ ×¤×©×¨×•×ª
    config.context.MAX_CONTEXT_TOKENS = 20000    # ×ž×§×¡×™×ž×•× ×’×‘×•×”
    config.context.RESERVED_TOKENS_FOR_RESPONSE = 6000  # ×ª×©×•×‘×•×ª ×ž×¤×•×¨×˜×•×ª
    config.context.CONTEXT_OVERLAP_TOKENS = 500  # overlap ×’×‘×•×” ×ž××•×“
    
    # ðŸŽ¯ LLM ×œ×“×™×•×§ ×ž×•×—×œ×˜
    config.llm.TEMPERATURE = 0.01                # ×›×ž×¢×˜ ×“×˜×¨×ž×™× ×™×¡×˜×™ ×œ×—×œ×•×˜×™×Ÿ
    config.llm.MAX_OUTPUT_TOKENS = 6000          # ×ª×©×•×‘×•×ª ×ž×§×™×¤×•×ª
    config.llm.TOP_P = 0.9                       # ×“×™×•×§ ×’×‘×•×”
    
    # âš¡ ×‘×™×¦×•×¢×™× - ×ž×”×™×¨×•×ª ×œ× ×¨×œ×•×•× ×˜×™×ª
    config.performance.TARGET_SEARCH_TIME_MS = 10000   # 10 ×©× ×™×•×ª - ×œ× ×ž×©× ×”
    config.performance.TARGET_GENERATION_TIME_MS = 15000  # 15 ×©× ×™×•×ª - ×œ× ×ž×©× ×”
    
    # ðŸ” ×›×œ ×”××•×¤×˜×™×ž×™×–×¦×™×•×ª ×”××¤×©×¨×™×•×ª
    config.optimization.ENABLE_DETAILED_LOGGING = True
    config.performance.LOG_SEARCH_ANALYTICS = True
    config.performance.LOG_PERFORMANCE_METRICS = True
    config.optimization.ENABLE_CHUNK_RERANKING = True
    
    # ðŸš€ timeouts ×’×‘×•×”×™× ×œ×¢×™×‘×•×“ ×ž×•×¨×›×‘
    config.search.SEARCH_TIMEOUT_SECONDS = 300   # 5 ×“×§×•×ª
    config.llm.GENERATION_TIMEOUT_SECONDS = 600  # 10 ×“×§×•×ª
    
    # ðŸŽ›ï¸ ×”×’×“×¨×•×ª ×ž×ª×§×“×ž×•×ª ×œ×“×™×•×§ ×ž×§×¡×™×ž×œ×™
    config.search.USE_QUERY_EXPANSION = True     # ×”×¨×—×‘×ª ×—×™×¤×•×©
    config.search.ENABLE_FUZZY_MATCHING = True   # ×”×ª××ž×” ×ž×¢×•×¨×¤×œ×ª
    config.context.ENABLE_CONTEXT_RERANKING = True  # ×“×™×¨×•×’ ×ž×—×“×© ×©×œ ×§×•× ×˜×§×¡×˜
    
    return config


# Dictionary of all profiles - ×—×™×™×‘ ×œ×”×™×•×ª ×œ×¤× ×™ ×”×˜×¢×™× ×” ×”×“×™× ×ž×™×ª
PROFILES = {
    "high_quality": get_high_quality_profile,
    "fast": get_fast_profile,
    "balanced": get_balanced_profile,
    "improved": get_improved_profile,
    "debug": get_debug_profile,
    "enhanced_testing": get_enhanced_testing_profile,
    "optimized_testing": get_optimized_testing_profile,
    "maximum_accuracy": get_maximum_accuracy_profile,
}

# ×˜×•×¢×Ÿ ×¤×¨×•×¤×™×œ×™× ×“×™× ×ž×™×™× ×ž×”×§×•×‘×¥ ×•×ž×•×¡×™×£ ××•×ª× ×œ-PROFILES
for profile_id, profile_data in dynamic_profiles_data.items():
    if profile_id not in PROFILES:  # ×¨×§ ×× ×œ× ×§×™×™× ×›×‘×¨
        PROFILES[profile_id] = lambda data=profile_data: create_profile_from_data(data)
        DYNAMIC_PROFILE_DESCRIPTIONS[profile_id] = profile_data.get('description', f'Custom profile: {profile_id}')

def save_new_profile(profile_id: str, profile_data: Dict[str, Any]) -> None:
    """×©×•×ž×¨ ×¤×¨×•×¤×™×œ ×—×“×© ×œ×§×•×‘×¥ ×•×ž×•×¡×™×£ ×œ×–×™×›×¨×•×Ÿ"""
    # Load existing profiles
    existing_profiles = load_dynamic_profiles()
    
    # Add new profile
    existing_profiles[profile_id] = profile_data
    
    # Save to file
    save_dynamic_profiles(existing_profiles)
    
    # Add to memory
    PROFILES[profile_id] = lambda: create_profile_from_data(profile_data)
    DYNAMIC_PROFILE_DESCRIPTIONS[profile_id] = profile_data.get('description', f'Custom profile: {profile_id}')

def delete_profile(profile_id: str) -> bool:
    """×ž×•×—×§ ×¤×¨×•×¤×™×œ (×¨×§ ×¤×¨×•×¤×™×œ×™× ×“×™× ×ž×™×™×)"""
    # ×•×“× ×©×–×” ×œ× ×¤×¨×•×¤×™×œ ×ž×•×‘× ×”
    built_in_profiles = {"high_quality", "fast", "balanced", "improved", "debug", 
                        "enhanced_testing", "optimized_testing", "maximum_accuracy"}
    
    if profile_id in built_in_profiles:
        return False  # ×œ× × ×™×ª×Ÿ ×œ×ž×—×•×§ ×¤×¨×•×¤×™×œ×™× ×ž×•×‘× ×™×
    
    # Load existing profiles
    existing_profiles = load_dynamic_profiles()
    
    if profile_id in existing_profiles:
        # Remove from file
        del existing_profiles[profile_id]
        save_dynamic_profiles(existing_profiles)
        
        # Remove from memory
        if profile_id in PROFILES:
            del PROFILES[profile_id]
        if profile_id in DYNAMIC_PROFILE_DESCRIPTIONS:
            del DYNAMIC_PROFILE_DESCRIPTIONS[profile_id]
        
        return True
    
    return False

def update_dynamic_profile_description(profile_id: str, description: str) -> None:
    """Update the description for a dynamically created profile"""
    global DYNAMIC_PROFILE_DESCRIPTIONS
    DYNAMIC_PROFILE_DESCRIPTIONS[profile_id] = description

def get_profile(profile_name: str) -> RAGConfig:
    """Returns profile by name"""
    if profile_name not in PROFILES:
        available = ", ".join(PROFILES.keys())
        raise ValueError(f"Profile '{profile_name}' does not exist. Available profiles: {available}")
    
    return PROFILES[profile_name]()


def list_profiles() -> Dict[str, str]:
    """Returns list of profiles with descriptions (excluding hidden profiles)"""
    # Load hidden profiles list
    hidden_profiles = load_hidden_profiles()
    
    # Static profile descriptions
    static_profiles = {
        "high_quality": "Maximum quality - high accuracy, lower speed",
        "fast": "Maximum speed - good performance, reasonable quality",
        "balanced": "Balanced - improved settings based on analysis",
        "improved": "Optimized for missing sections - very low threshold, small chunks",
        "debug": "Debug and development - detailed logs, low thresholds",
        "enhanced_testing": "Enhanced Testing (AGGRESSIVE) - Based on 66.7% failure analysis",
        "optimized_testing": "Optimized Testing - Balanced performance & accuracy (73.3% analysis)",
        "maximum_accuracy": "Maximum Accuracy - No performance limits (Target: 98-100%)",
    }
    
    # Filter out hidden built-in profiles
    visible_static_profiles = {
        profile_id: description 
        for profile_id, description in static_profiles.items() 
        if profile_id not in hidden_profiles
    }
    
    # Add dynamically created profiles
    dynamic_profiles = {}
    for profile_id in PROFILES.keys():
        if profile_id not in static_profiles:
            # Use stored description if available, otherwise generic description
            description = DYNAMIC_PROFILE_DESCRIPTIONS.get(profile_id, f"Custom profile: {profile_id}")
            dynamic_profiles[profile_id] = description
    
    # Combine visible static and dynamic profiles
    return {**visible_static_profiles, **dynamic_profiles}


def compare_profiles(profile1_name: str, profile2_name: str) -> Dict[str, Any]:
    """Compares two profiles"""
    profile1 = get_profile(profile1_name)
    profile2 = get_profile(profile2_name)
    
    comparison = {
        "similarity_threshold": {
            profile1_name: profile1.search.SIMILARITY_THRESHOLD,
            profile2_name: profile2.search.SIMILARITY_THRESHOLD
        },
        "max_chunks": {
            profile1_name: profile1.search.MAX_CHUNKS_RETRIEVED,
            profile2_name: profile2.search.MAX_CHUNKS_RETRIEVED
        },
        "context_tokens": {
            profile1_name: profile1.context.MAX_CONTEXT_TOKENS,
            profile2_name: profile2.context.MAX_CONTEXT_TOKENS
        },
        "temperature": {
            profile1_name: profile1.llm.TEMPERATURE,
            profile2_name: profile2.llm.TEMPERATURE
        },
        "semantic_weight": {
            profile1_name: profile1.search.HYBRID_SEMANTIC_WEIGHT,
            profile2_name: profile2.search.HYBRID_SEMANTIC_WEIGHT
        }
    }
    
    return comparison


if __name__ == "__main__":
    print("ðŸ”§ RAG Configuration Profiles")
    print("=" * 50)
    
    # Display all profiles
    profiles_info = list_profiles()
    for name, description in profiles_info.items():
        print(f"\nðŸ“‹ {name.upper()}:")
        print(f"   {description}")
        
        # Display key settings
        profile = get_profile(name)
        print(f"   ðŸ“Š Key settings:")
        print(f"      Similarity threshold: {profile.search.SIMILARITY_THRESHOLD}")
        print(f"      Max chunks: {profile.search.MAX_CHUNKS_RETRIEVED}")
        print(f"      Context tokens: {profile.context.MAX_CONTEXT_TOKENS}")
        print(f"      Temperature: {profile.llm.TEMPERATURE}")
        print(f"      Semantic/Keyword weights: {profile.search.HYBRID_SEMANTIC_WEIGHT}/{profile.search.HYBRID_KEYWORD_WEIGHT}")
    
    print(f"\nðŸ“ˆ Comparison: fast vs high_quality")
    comparison = compare_profiles("fast", "high_quality")
    for metric, values in comparison.items():
        print(f"   {metric}: {values}")
