#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
××¢×¨×›×ª ×‘×“×™×§×” ××œ××” ×œRAG - ××›×œ×œ×ª ××¤×§×”
=====================================

×¡×§×¨×™×¤×˜ ×–×” ××¨×™×¥ ×‘×“×™×§×” ××§×™×¤×” ×©×œ ××¢×¨×›×ª ×”-RAG ×•×™×•×¦×¨ ×“×•×—×•×ª ××¤×•×¨×˜×™×.
"""

import os
import sys
import json
import time
import asyncio
import logging
from datetime import datetime
from typing import Dict, List, Any, Optional
from pathlib import Path

# Add the project root to sys.path to allow importing from src
current_dir = Path(__file__).parent
project_root = current_dir.parent
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))

# Also add backend directory for app imports
backend_dir = project_root / "src" / "backend"
if str(backend_dir) not in sys.path:
    sys.path.insert(0, str(backend_dir))

try:
    from app.config.settings import settings
    # ×œ× × ×™×™×‘× ××ª RAGService ×›××Ÿ - × ×¢×©×” ×–××ª ×‘×¤×•× ×§×¦×™×™×ª ×”××ª×—×•×œ
except ImportError as e:
    print(f"×©×’×™××” ×‘×™×™×‘×•× ××•×“×•×œ×™×: {e}")
    print("×•×•×“× ×©××ª×” ××¨×™×¥ ××ª ×”×¡×§×¨×™×¤×˜ ××”×ª×™×§×™×™×” ×”×¨××©×™×ª ×©×œ ×”×¤×¨×•×™×§×˜")
    sys.exit(1)

# ×”×’×“×¨×ª ×œ×•×’×™× ×’
# ×™×¦×™×¨×ª ×ª×™×§×™×™×ª results ×× ×œ× ×§×™×™××ª
results_dir = current_dir / 'results'
results_dir.mkdir(exist_ok=True)

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler(results_dir / 'test_debug.log', encoding='utf-8')
    ]
)

logger = logging.getLogger(__name__)

class RAGTester:
    """××—×œ×§×” ×œ×‘×“×™×§×ª ××¢×¨×›×ª RAG"""
    
    def __init__(self, auto_select=True):
        self.rag_service = None
        self.test_results = []
        self.start_time = None
        self.end_time = None
        self.timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.selected_question_set = None
        self.selected_profile = None
        self.multiple_sets_mode = False
        self.all_question_sets = []
        
        if auto_select:
            # ×‘×—×™×¨×ª ×¤×¨×•×¤×™×œ
            self.selected_profile = self.select_rag_profile()
            
            # ×‘×—×™×¨×ª ×¡×˜ ×©××œ×•×ª
            self.questions = self.select_question_set()
        else:
            self.questions = []
    
    def select_rag_profile(self) -> str:
        """×‘×—×™×¨×ª ×¤×¨×•×¤×™×œ RAG ×œ×‘×“×™×§×”"""
        try:
            from src.ai.config.rag_config_profiles import list_profiles
            
            profiles_info = list_profiles()
            
            print("\nğŸ”§ Available RAG Profiles:")
            print("=" * 50)
            
            # ×”×¦×’×ª ×”×¤×¨×•×¤×™×œ×™× ×”×–××™× ×™×
            profile_list = list(profiles_info.items())
            for i, (profile_name, description) in enumerate(profile_list, 1):
                print(f"{i}. {profile_name.replace('_', ' ').title()}")
                print(f"   ğŸ“ {description}")
                print()
            
            # ×‘×—×™×¨×ª ×”××©×ª××©
            while True:
                try:
                    choice = input(f"Please select a RAG profile (1-{len(profile_list)}): ").strip()
                    
                    if choice.lower() in ['quit', 'exit', 'q']:
                        print("ğŸ‘‹ Exiting...")
                        sys.exit(0)
                    
                    choice_num = int(choice)
                    if 1 <= choice_num <= len(profile_list):
                        selected_profile_name = profile_list[choice_num - 1][0]
                        selected_profile_desc = profile_list[choice_num - 1][1]
                        
                        print(f"\nâœ… Selected Profile: {selected_profile_name.replace('_', ' ').title()}")
                        print(f"ğŸ“ {selected_profile_desc}")
                        print()
                        
                        return selected_profile_name
                    else:
                        print(f"âŒ Please enter a number between 1 and {len(profile_list)}")
                        
                except ValueError:
                    print("âŒ Please enter a valid number")
                except KeyboardInterrupt:
                    print("\nğŸ‘‹ Exiting...")
                    sys.exit(0)
                    
        except ImportError as e:
            print(f"âš ï¸  Could not load profiles: {e}")
            print("ğŸ”„ Using default profile...")
            return "balanced"
    
    def select_question_set(self) -> List[Dict[str, Any]]:
        """×‘×—×™×¨×ª ×¡×˜ ×©××œ×•×ª ×œ×‘×“×™×§×”"""
        questions_dir = Path(__file__).parent / 'test_questions'
        
        # ××¦×™××ª ×›×œ ×§×‘×¦×™ JSON ×‘×ª×™×§×™×™×ª ×”×©××œ×•×ª
        question_files = list(questions_dir.glob('*.json'))
        
        if not question_files:
            raise FileNotFoundError("No question files found in test_questions directory")
        
        print("\nğŸ§ª Available Question Sets:")
        print("=" * 50)
        
        # ×˜×¢×™× ×” ×•×”×¦×’×ª ××™×“×¢ ×¢×œ ×›×œ ×¡×˜ ×©××œ×•×ª
        available_sets = []
        for i, file_path in enumerate(question_files, 1):
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                # × ×™×¡×™×•×Ÿ ×œ×—×œ×¥ ××™×“×¢ ×¢×œ ×”×¡×˜
                name = data.get('name', file_path.stem.replace('_', ' ').title())
                description = data.get('description', 'No description available')
                question_count = len(data.get('questions', []))
                
                available_sets.append({
                    'index': i,
                    'file_path': file_path,
                    'name': name,
                    'description': description,
                    'question_count': question_count,
                    'data': data
                })
                
                print(f"{i}. {name}")
                print(f"   ğŸ“ {description}")
                print(f"   ğŸ“Š {question_count} questions")
                print()
                
            except Exception as e:
                print(f"âš ï¸  Error loading {file_path.name}: {e}")
        
        if not available_sets:
            raise ValueError("No valid question sets found")
        
        # ×”×•×¡×¤×ª ××•×¤×¦×™×” ×œ×›×œ ×”×¡×˜×™×
        print(f"{len(available_sets) + 1}. ğŸ”„ ALL QUESTION SETS IN SEQUENCE")
        print(f"   ğŸ“ Run all question sets one after another")
        total_questions = sum(s['question_count'] for s in available_sets)
        print(f"   ğŸ“Š {total_questions} questions total")
        print()
        
        # ×‘×—×™×¨×ª ×”××©×ª××©
        while True:
            try:
                choice = input(f"Please select a question set (1-{len(available_sets) + 1}): ").strip()
                
                if choice.lower() in ['quit', 'exit', 'q']:
                    print("ğŸ‘‹ Exiting...")
                    sys.exit(0)
                
                choice_num = int(choice)
                
                # ××•×¤×¦×™×” ×©×œ ×›×œ ×”×¡×˜×™×
                if choice_num == len(available_sets) + 1:
                    self.selected_question_set = "All Question Sets Combined"
                    self.multiple_sets_mode = True
                    self.all_question_sets = available_sets
                    
                    print(f"\nâœ… Selected: ALL QUESTION SETS")
                    print(f"ğŸ“Š Will run {len(available_sets)} sets with {total_questions} total questions")
                    print(f"ğŸ”„ Sequence: {' â†’ '.join([s['name'] for s in available_sets])}")
                    
                    # ××™×—×•×“ ×›×œ ×”×©××œ×•×ª
                    all_questions = []
                    for set_info in available_sets:
                        for question in set_info['data']['questions']:
                            # ×”×•×¡×¤×ª ××™×“×¢ ×¢×œ ×”×¡×˜ ××”× ×•×©×
                            question_with_set = question.copy()
                            question_with_set['source_set'] = set_info['name']
                            question_with_set['set_index'] = set_info['index']
                            all_questions.append(question_with_set)
                    
                    return all_questions
                
                # ×‘×—×™×¨×ª ×¡×˜ ×™×—×™×“
                elif 1 <= choice_num <= len(available_sets):
                    selected_set = available_sets[choice_num - 1]
                    self.selected_question_set = selected_set['name']
                    self.multiple_sets_mode = False
                    
                    print(f"\nâœ… Selected: {selected_set['name']}")
                    print(f"ğŸ“Š Loading {selected_set['question_count']} questions...")
                    
                    return selected_set['data']['questions']
                else:
                    print(f"âŒ Please enter a number between 1 and {len(available_sets) + 1}")
                    
            except ValueError:
                print("âŒ Please enter a valid number")
            except KeyboardInterrupt:
                print("\nğŸ‘‹ Exiting...")
                sys.exit(0)
    
    async def initialize_services(self):
        """××ª×—×•×œ ×©×™×¨×•×ª×™×"""
        try:
            logger.info(f"×××ª×—×œ ×©×™×¨×•×ª×™ RAG ×¢× ×¤×¨×•×¤×™×œ: {self.selected_profile}...")
            
            # ×˜×¢×™× ×ª ×”×¤×¨×•×¤×™×œ ×©× ×‘×—×¨
            from src.ai.config.rag_config_profiles import get_profile
            profile_config = get_profile(self.selected_profile)
            
            # ××—×™×§×ª ××•×“×•×œ×™× ×©×›×‘×¨ × ×˜×¢× ×•
            import sys
            modules_to_clear = [
                'src.ai.config.rag_config',
                'src.ai.services.rag_service',
                'src.ai.config.current_profile'
            ]
            for module in modules_to_clear:
                if module in sys.modules:
                    del sys.modules[module]
            
            # ×™×¦×™×¨×ª RAGService ×¢× ×”×¤×¨×•×¤×™×œ ×©× ×‘×—×¨ ×™×©×™×¨×•×ª
            from src.ai.services.rag_service import RAGService
            self.rag_service = RAGService(config_profile=self.selected_profile)
            
            # ×•×™×“×•× ×©×”×¤×¨×•×¤×™×œ × ×˜×¢×Ÿ
            logger.info(f"âœ… ×©×™×¨×•×ª×™× ××•×ª×—×œ×• ×‘×”×¦×œ×—×” ×¢× ×¤×¨×•×¤×™×œ: {self.selected_profile}")
            logger.info(f"ğŸ¯ ×”×’×“×¨×•×ª × ×˜×¢× ×•: threshold={profile_config.search.SIMILARITY_THRESHOLD}, chunks={profile_config.search.MAX_CHUNKS_RETRIEVED}")
            logger.info(f"ğŸ” ××§×¡×™××œ×™ ×¦'×× ×§×™× ×‘×§×•× ×˜×§×¡×˜: {profile_config.search.MAX_CHUNKS_FOR_CONTEXT}")
            logger.info(f"ğŸ“Š ×’×•×“×œ ×¦'×× ×§: {profile_config.chunk.DEFAULT_CHUNK_SIZE}, overlap: {profile_config.chunk.DEFAULT_CHUNK_OVERLAP}")
            
        except Exception as e:
            logger.error(f"×©×’×™××” ×‘××ª×—×•×œ ×©×™×¨×•×ª×™×: {e}")
            raise
    
    def extract_current_settings(self) -> Dict[str, Any]:
        """×—×™×œ×•×¥ ×”×’×“×¨×•×ª RAG × ×•×›×—×™×•×ª"""
        return {
            "timestamp": self.timestamp,
            "selected_question_set": self.selected_question_set,
            "selected_profile": self.selected_profile,
            "total_questions_in_set": len(self.questions),
            "rag_settings": {
                "profile_used": self.selected_profile,
                "max_context_tokens": getattr(self.rag_service, 'max_context_tokens', 'N/A'),
                "similarity_threshold": getattr(self.rag_service, 'similarity_threshold', 'N/A'),
                "max_chunks": getattr(self.rag_service, 'max_chunks', 'N/A'),
                "embedding_model": "models/embedding-001",
                "llm_model": getattr(self.rag_service, 'model', {}).model_name if hasattr(self.rag_service, 'model') else 'N/A'
            },
            "chat_settings": {
                "gemini_model": settings.GEMINI_MODEL_NAME,
                "temperature": settings.GEMINI_TEMPERATURE,
                "max_tokens": settings.GEMINI_MAX_TOKENS,
                "history_window": settings.LANGCHAIN_HISTORY_K
            },
            "system_info": {
                "python_version": sys.version,
                "working_directory": os.getcwd()
            }
        }
    
    async def test_single_question(self, question_data: Dict[str, Any]) -> Dict[str, Any]:
        """×‘×“×™×§×ª ×©××œ×” ×™×—×™×“×”"""
        logger.info(f"×‘×•×“×§ ×©××œ×” #{question_data['id']}: {question_data['question']}")
        
        start_time = time.time()
        
        try:
            # ×‘×™×¦×•×¢ ×”×—×™×¤×•×© ×‘×××¦×¢×•×ª RAG service
            rag_result = await self.rag_service.generate_answer(
                query=question_data['question'],
                search_method="hybrid"
            )
            
            response_time = (time.time() - start_time) * 1000  # ×‘××™×œ×™×©× ×™×•×ª
            
            # × ×™×ª×•×— ×”×ª×•×¦××•×ª
            chunks_info = []
            if 'chunks_selected' in rag_result:
                for i, chunk in enumerate(rag_result['chunks_selected']):
                    chunk_info = {
                        "chunk_id": chunk.get('chunk_id', f'chunk_{i}'),
                        "similarity_score": chunk.get('similarity_score', chunk.get('combined_score', 0)),
                        "section_detected": chunk.get('section', '×œ× ×–×•×”×”'),
                        "content_preview": chunk.get('chunk_text', '')[:100] + "..." if chunk.get('chunk_text') else '',
                        "metadata": {
                            "document": chunk.get('document_name', '×œ× ×–×•×”×”'),
                            "page": chunk.get('page_number', '×œ× ×–×•×”×”'),
                            "chunk_header": chunk.get('chunk_header', '×œ× ×–×•×”×”')
                        }
                    }
                    chunks_info.append(chunk_info)
            
            # ×”×¢×¨×›×ª ×“×™×•×§
            accuracy = self.assess_accuracy(question_data, rag_result, chunks_info)
            
            result = {
                "question_id": question_data['id'],
                "category": question_data['category'],
                "question": question_data['question'],
                "expected_section": question_data['expected_section'],
                "expected_content": question_data['expected_content'],
                "difficulty": question_data['difficulty'],
                "timestamp": datetime.now().isoformat(),
                "response_time_ms": round(response_time, 2),
                "answer": rag_result.get('answer', '×œ× ×”×ª×§×‘×œ×” ×ª×©×•×‘×”'),
                "chunks_selected": chunks_info,
                "total_chunks_retrieved": len(chunks_info),
                "sources_count": len(rag_result.get('sources', [])),
                "context_tokens_estimated": self.estimate_tokens(rag_result.get('answer', '')),
                "accuracy_assessment": accuracy,
                "raw_rag_result": rag_result  # ×œ×¦×•×¨×š ×“×™×‘×•×’
            }
            
            return result
            
        except Exception as e:
            logger.error(f"×©×’×™××” ×‘×‘×“×™×§×ª ×©××œ×” #{question_data['id']}: {e}")
            return {
                "question_id": question_data['id'],
                "category": question_data['category'],
                "question": question_data['question'],
                "error": str(e),
                "timestamp": datetime.now().isoformat(),
                "response_time_ms": (time.time() - start_time) * 1000
            }
    
    def assess_accuracy(self, question_data: Dict[str, Any], rag_result: Dict[str, Any], chunks_info: List[Dict]) -> Dict[str, Any]:
        """×”×¢×¨×›×ª ×“×™×•×§ ×”×ª×©×•×‘×”"""
        answer = rag_result.get('answer', '') or ''
        answer = answer.lower() if answer else ''
        expected_section = question_data.get('expected_section', '') or ''
        expected_section = expected_section.lower() if expected_section else ''
        
        # ×‘×“×™×§×” ×× ×”×¡×¢×™×£ ×”× ×›×•×Ÿ × ××¦×
        correct_section = False
        if expected_section != 'multiple' and expected_section != 'none':
            correct_section = expected_section in answer
            # ×‘×“×™×§×” ×’× ×‘×¦'×× ×§×™×
            if not correct_section:
                for chunk in chunks_info:
                    section_detected = chunk.get('section_detected', '') or ''
                    if section_detected and expected_section in section_detected.lower():
                        correct_section = True
                        break
        elif expected_section == 'multiple':
            correct_section = len(chunks_info) > 0  # ×× ××¦× ××©×”×• ×¨×œ×•×•× ×˜×™
        elif expected_section == 'none':
            correct_section = len(chunks_info) == 0 or "×œ× × ××¦×" in answer or "××™×Ÿ ××™×“×¢" in answer
        
        # ×‘×“×™×§×ª ×©×œ××•×ª ×”×ª×©×•×‘×”
        complete_answer = len(answer) > 50 and "×œ× × ××¦×" not in answer
        
        # ×‘×“×™×§×ª ×¨×œ×•×•× ×˜×™×•×ª
        relevant_content = len(chunks_info) > 0 and any(
            chunk['similarity_score'] > 0.6 for chunk in chunks_info
        )
        
        # ×§×‘×™×¢×ª ×¡×•×’ ×©×’×™××”
        error_type = "none"
        if not correct_section:
            error_type = "wrong_section"
        elif not complete_answer:
            error_type = "incomplete"
        elif not relevant_content:
            error_type = "irrelevant"
        
        return {
            "correct_section": correct_section,
            "complete_answer": complete_answer,
            "relevant_content": relevant_content,
            "error_type": error_type,
            "overall_success": correct_section and complete_answer and relevant_content
        }
    
    def estimate_tokens(self, text: str) -> int:
        """×”×¢×¨×›×ª ××¡×¤×¨ ×˜×•×§× ×™×"""
        return int(len(text.split()) * 1.3)  # ×”×¢×¨×›×” ×’×¡×”
    
    async def run_all_tests(self):
        """×”×¨×¦×ª ×›×œ ×”×‘×“×™×§×•×ª"""
        logger.info("××ª×—×™×œ ×‘×“×™×§×•×ª RAG...")
        self.start_time = datetime.now()
        
        await self.initialize_services()
        
        for question in self.questions:
            result = await self.test_single_question(question)
            self.test_results.append(result)
            
            # ×”××ª× ×” ×§×¦×¨×” ×‘×™×Ÿ ×©××œ×•×ª
            await asyncio.sleep(0.5)
        
        self.end_time = datetime.now()
        logger.info("×‘×“×™×§×•×ª ×”×•×©×œ××•!")
    
    def generate_summary_stats(self) -> Dict[str, Any]:
        """×™×¦×™×¨×ª ×¡×˜×˜×™×¡×˜×™×§×•×ª ×¡×™×›×•×"""
        total_questions = len(self.test_results)
        successful_tests = [r for r in self.test_results if 'error' not in r]
        
        if not successful_tests:
            return {"error": "×œ× ×”×¦×œ×™×—×” ××£ ×‘×“×™×§×”"}
        
        # ×¡×˜×˜×™×¡×˜×™×§×•×ª ×›×œ×œ×™×•×ª
        correct_answers = sum(1 for r in successful_tests 
                            if r.get('accuracy_assessment', {}).get('overall_success', False))
        partial_answers = sum(1 for r in successful_tests 
                            if r.get('accuracy_assessment', {}).get('correct_section', False) 
                            and not r.get('accuracy_assessment', {}).get('overall_success', False))
        wrong_answers = total_questions - correct_answers - partial_answers
        
        # ×–××Ÿ ×ª×’×•×‘×” ×××•×¦×¢
        avg_response_time = sum(r.get('response_time_ms', 0) for r in successful_tests) / len(successful_tests)
        
        # ×¡×˜×˜×™×¡×˜×™×§×•×ª ×œ×¤×™ ×§×˜×’×•×¨×™×”
        categories_stats = {}
        for result in successful_tests:
            category = result.get('category', '×œ× ×–×•×”×”')
            if category not in categories_stats:
                categories_stats[category] = {'total': 0, 'correct': 0}
            categories_stats[category]['total'] += 1
            if result.get('accuracy_assessment', {}).get('overall_success', False):
                categories_stats[category]['correct'] += 1
        
        # ×¡×˜×˜×™×¡×˜×™×§×•×ª ×œ×¤×™ ×¡×˜ ×©××œ×•×ª (×× ×¨×¥ ×¢×œ ×›×œ ×”×¡×˜×™×)
        sets_stats = {}
        if self.multiple_sets_mode:
            for result in successful_tests:
                source_set = result.get('source_set', '×œ× ×–×•×”×”')
                if source_set not in sets_stats:
                    sets_stats[source_set] = {'total': 0, 'correct': 0}
                sets_stats[source_set]['total'] += 1
                if result.get('accuracy_assessment', {}).get('overall_success', False):
                    sets_stats[source_set]['correct'] += 1
        
        return {
            "total_questions": total_questions,
            "correct_answers": correct_answers,
            "partial_answers": partial_answers,
            "wrong_answers": wrong_answers,
            "success_rate": (correct_answers / total_questions) * 100,
            "partial_rate": (partial_answers / total_questions) * 100,
            "error_rate": (wrong_answers / total_questions) * 100,
            "avg_response_time_ms": round(avg_response_time, 2),
            "categories_stats": categories_stats,
            "sets_stats": sets_stats if self.multiple_sets_mode else {},
            "test_duration_seconds": (self.end_time - self.start_time).total_seconds(),
            "multiple_sets_mode": self.multiple_sets_mode
        }
    
    def generate_recommendations(self, stats: Dict[str, Any]) -> List[str]:
        """×™×¦×™×¨×ª ×”××œ×¦×•×ª ×œ×©×™×¤×•×¨"""
        recommendations = []
        
        success_rate = stats.get('success_rate', 0)
        avg_response_time = stats.get('avg_response_time_ms', 0)
        
        # ×”××œ×¦×•×ª ×¢×œ ×¡××š ×©×™×¢×•×¨ ×”×¦×œ×—×”
        if success_rate < 70:
            recommendations.append("ğŸš¨ ×©×™×¢×•×¨ ×”×¦×œ×—×” × ××•×š - ×”× ××š ××ª ×¡×£ ×”×“××™×•×Ÿ ×œ-0.5")
            recommendations.append("ğŸ”§ ×”×’×“×œ ××ª ××¡×¤×¨ ×”×¦'×× ×§×™× ×”× ×©×œ×¤×™× ×œ-12")
        elif success_rate < 85:
            recommendations.append("âš ï¸ ×©×™×¢×•×¨ ×”×¦×œ×—×” ×‘×™× ×•× ×™ - ×©×§×•×œ ×œ×”×’×“×™×œ ××ª ××¡×¤×¨ ×”×¦'×× ×§×™× ×‘×§×•× ×˜×§×¡×˜")
        
        # ×”××œ×¦×•×ª ×¢×œ ×¡××š ×–××Ÿ ×ª×’×•×‘×”
        if avg_response_time > 3000:
            recommendations.append("â±ï¸ ×–××Ÿ ×ª×’×•×‘×” ××™×˜×™ - ×©×§×•×œ ×œ×”×§×˜×™×Ÿ ××ª ××¡×¤×¨ ×”×¦'×× ×§×™×")
            recommendations.append("ğŸš€ ×©×§×•×œ ××•×¤×˜×™××™×–×¦×™×” ×©×œ ×—×™×¤×•×© ×‘××¡×“ ×”× ×ª×•× ×™×")
        
        # ×”××œ×¦×•×ª ×¡×¤×¦×™×¤×™×•×ª ×œ×§×˜×’×•×¨×™×•×ª
        categories = stats.get('categories_stats', {})
        for category, cat_stats in categories.items():
            success_rate_cat = (cat_stats['correct'] / cat_stats['total']) * 100 if cat_stats['total'] > 0 else 0
            if success_rate_cat < 60:
                recommendations.append(f"ğŸ“š ×§×˜×’×•×¨×™×” '{category}': ×©×™×¢×•×¨ ×”×¦×œ×—×” × ××•×š ({success_rate_cat:.1f}%) - ×©×¤×¨ ×–×™×”×•×™ ××™×œ×•×ª ××¤×ª×—")
        
        # ×‘×“×™×§×” ×œ×’×‘×™ ×©××œ×•×ª ××œ×›×•×“×ª
        trap_questions = [r for r in self.test_results if r.get('difficulty') == 'trap']
        trap_success = sum(1 for r in trap_questions if '×œ× × ××¦×' in r.get('answer', '') or '××™×Ÿ ××™×“×¢' in r.get('answer', ''))
        if len(trap_questions) > 0 and (trap_success / len(trap_questions)) < 0.5:
            recommendations.append("ğŸª¤ ×‘×¢×™×” ×‘×–×™×”×•×™ ×©××œ×•×ª ××œ×›×•×“×ª - ×©×¤×¨ ×”× ×“×œ×™× ×’ ×©×œ ×ª×©×•×‘×•×ª '×œ× × ××¦×'")
        
        if not recommendations:
            recommendations.append("âœ… ××¢×¨×›×ª ×”-RAG ×¢×•×‘×“×ª ×‘×¦×•×¨×” ××¦×•×™× ×ª!")
        
        return recommendations
    
    def save_detailed_report(self):
        """×©××™×¨×ª ×“×•×— ××¤×•×¨×˜"""
        settings_data = self.extract_current_settings()
        stats = self.generate_summary_stats()
        recommendations = self.generate_recommendations(stats)
        
        # ×™×¦×™×¨×ª × ×ª×™×‘ ×ª×™×§×™×™×ª results
        results_dir = Path(__file__).parent / 'results'
        results_dir.mkdir(exist_ok=True)
        
        # ×©××™×¨×ª ×”×’×“×¨×•×ª ×œ××•×‘×Ÿ JSON
        with open(results_dir / f'rag_settings_{self.timestamp}.json', 'w', encoding='utf-8') as f:
            json.dump(settings_data, f, ensure_ascii=False, indent=2)
        
        # ×™×¦×™×¨×ª ×“×•×— ×˜×§×¡×˜ ××¤×•×¨×˜
        report_content = self.create_detailed_text_report(stats, recommendations)
        with open(results_dir / f'test_report_{self.timestamp}.txt', 'w', encoding='utf-8') as f:
            f.write(report_content)
        
        # ×©××™×¨×ª × ×™×ª×•×— ×¦'×× ×§×™×
        chunks_analysis = self.create_chunks_analysis()
        with open(results_dir / f'chunks_analysis_{self.timestamp}.txt', 'w', encoding='utf-8') as f:
            f.write(chunks_analysis)
        
        # ×©××™×¨×ª × ×ª×•× ×™× ×’×•×œ××™×™× JSON
        with open(results_dir / f'raw_results_{self.timestamp}.json', 'w', encoding='utf-8') as f:
            json.dump(self.test_results, f, ensure_ascii=False, indent=2)
        
        logger.info(f"×“×•×—×•×ª × ×©××¨×• ×‘×ª×™×§×™×™×ª {results_dir} ×¢× ×—×•×ª××ª ×–××Ÿ {self.timestamp}")
    
    def create_detailed_text_report(self, stats: Dict[str, Any], recommendations: List[str]) -> str:
        """×™×¦×™×¨×ª ×“×•×— ×˜×§×¡×˜ ××¤×•×¨×˜"""
        
        report = f"""===============================================
ğŸ§ª ×“×•×— ×‘×“×™×§×ª ××¢×¨×›×ª RAG - ××›×œ×œ×ª ××¤×§×”
===============================================
ğŸ“… ×ª××¨×™×š: {self.start_time.strftime('%Y-%m-%d %H:%M:%S')}
â±ï¸ ××©×š ×‘×“×™×§×”: {stats.get('test_duration_seconds', 0):.1f} ×©× ×™×•×ª
ğŸ”§ ×’×¨×¡×ª ××¢×¨×›×ª: v2.1.3
ğŸ›ï¸ ×¤×¨×•×¤×™×œ RAG: {self.selected_profile.replace('_', ' ').title()}
ğŸ“‹ ×¡×˜ ×©××œ×•×ª: {self.selected_question_set}
ğŸ”¢ ××¡×¤×¨ ×©××œ×•×ª: {len(self.questions)}

ğŸ“Š ×”×’×“×¨×•×ª RAG × ×•×›×—×™×•×ª:
----------------------------------------
ğŸ”¸ ××§×¡ ×˜×•×§× ×™× ×‘×§×•× ×˜×§×¡×˜: {self.rag_service.context_config.MAX_CONTEXT_TOKENS if self.rag_service else 'N/A'}
ğŸ”¸ ×¡×£ ×“××™×•×Ÿ: {self.rag_service.search_config.SIMILARITY_THRESHOLD if self.rag_service else 'N/A'}
ğŸ”¸ ××§×¡ ×¦'×× ×§×™×: {self.rag_service.search_config.MAX_CHUNKS_RETRIEVED if self.rag_service else 'N/A'}
ğŸ”¸ ××•×“×œ embedding: {self.rag_service.embedding_config.MODEL_NAME if self.rag_service else 'models/embedding-001'}
ğŸ”¸ ××•×“×œ LLM: {self.rag_service.llm_config.MODEL_NAME if self.rag_service else 'N/A'}
ğŸ”¸ ×˜××¤×¨×˜×•×¨×”: {self.rag_service.llm_config.TEMPERATURE if self.rag_service else 'N/A'}
ğŸ”¸ ××§×¡ ×˜×•×§× ×™×: {self.rag_service.llm_config.MAX_OUTPUT_TOKENS if self.rag_service else 'N/A'}

ğŸ“ˆ ×¡×™×›×•× ×ª×•×¦××•×ª:
----------------------------------------
âœ… ×ª×©×•×‘×•×ª × ×›×•× ×•×ª: {stats.get('correct_answers', 0)}/{stats.get('total_questions', 0)} ({stats.get('success_rate', 0):.1f}%)
âš ï¸ ×ª×©×•×‘×•×ª ×—×œ×§×™×•×ª: {stats.get('partial_answers', 0)}/{stats.get('total_questions', 0)} ({stats.get('partial_rate', 0):.1f}%)
âŒ ×ª×©×•×‘×•×ª ×©×’×•×™×•×ª: {stats.get('wrong_answers', 0)}/{stats.get('total_questions', 0)} ({stats.get('error_rate', 0):.1f}%)
â±ï¸ ×–××Ÿ ×ª×’×•×‘×” ×××•×¦×¢: {stats.get('avg_response_time_ms', 0):.1f} ××™×œ×™×©× ×™×•×ª

ğŸ¯ ×“×™×•×§ ×œ×¤×™ ×§×˜×’×•×¨×™×•×ª:
----------------------------------------"""
        
        for category, cat_stats in stats.get('categories_stats', {}).items():
            success_rate = (cat_stats['correct'] / cat_stats['total']) * 100 if cat_stats['total'] > 0 else 0
            report += f"\nğŸ”¹ {category}: {cat_stats['correct']}/{cat_stats['total']} ({success_rate:.1f}%)"
        
        # ×¡×˜×˜×™×¡×˜×™×§×•×ª ×œ×¤×™ ×¡×˜ ×©××œ×•×ª (×× ×–×” multiple sets mode)
        if stats.get('multiple_sets_mode', False) and stats.get('sets_stats'):
            report += f"""

ğŸ“Š ×‘×™×¦×•×¢×™× ×œ×¤×™ ×¡×˜ ×©××œ×•×ª:
----------------------------------------"""
            sets_stats = stats.get('sets_stats', {})
            for set_name, set_stats in sets_stats.items():
                success_rate = (set_stats['correct'] / set_stats['total']) * 100 if set_stats['total'] > 0 else 0
                report += f"\nğŸ”¸ {set_name}: {set_stats['correct']}/{set_stats['total']} ({success_rate:.1f}%)"
        
        report += f"""

===============================================
ğŸ“‹ ×ª×•×¦××•×ª ××¤×•×¨×˜×•×ª ×œ×›×œ ×©××œ×”:
===============================================
"""
        
        for result in self.test_results:
            if 'error' in result:
                report += f"""
âŒ ×©××œ×” #{result['question_id']}: "{result['question']}"
----------------------------------------
âš ï¸ ×©×’×™××”: {result['error']}
â±ï¸ ×–××Ÿ ×ª×’×•×‘×”: {result.get('response_time_ms', 0):.1f} ××™×œ×™×©× ×™×•×ª

"""
                continue
            
            accuracy = result.get('accuracy_assessment', {})
            chunks = result.get('chunks_selected', [])
            
            # ××™×™×§×•×Ÿ ×œ×¤×™ ×”×¦×œ×—×”
            if accuracy.get('overall_success', False):
                icon = "âœ…"
            elif accuracy.get('correct_section', False):
                icon = "âš ï¸"
            else:
                icon = "âŒ"
            
            report += f"""
{icon} ×©××œ×” #{result['question_id']}: "{result['question']}"
----------------------------------------
ğŸ“‚ ×§×˜×’×•×¨×™×”: {result['category']}
ğŸ¯ ×¨××ª ×§×•×©×™: {result['difficulty']}
â±ï¸ ×–××Ÿ ×ª×’×•×‘×”: {result['response_time_ms']:.1f} ××™×œ×™×©× ×™×•×ª
ğŸ“ ×¡×¢×™×£ ××¦×•×¤×”: {result['expected_section']}

ğŸ§© ×¦'×× ×§×™× ×©× ×‘×—×¨×• ({len(chunks)} ×¡×”"×›):"""
            
            for i, chunk in enumerate(chunks[:5]):  # ××¦×™×’ ×¨×§ 5 ×¨××©×•× ×™×
                report += f"""
  ğŸ“„ chunk_{i+1} (×“××™×•×Ÿ: {chunk.get('similarity_score', 0):.2f}) - {chunk.get('section_detected', '×œ× ×–×•×”×”')}"""
            
            if len(chunks) > 5:
                report += f"\n  ... ×•×¢×•×“ {len(chunks) - 5} ×¦'×× ×§×™×"
            
            # ×ª×•×¦××•×ª ×”×¢×¨×›×”
            report += f"""

ğŸ’¬ ×”×ª×©×•×‘×”:
"{result['answer'][:200]}{'...' if len(result['answer']) > 200 else ''}"

âœ… ×”×¢×¨×›×ª ×“×™×•×§:
  {'âœ…' if accuracy.get('correct_section') else 'âŒ'} ×¡×¢×™×£ × ×›×•×Ÿ: {'×›×Ÿ' if accuracy.get('correct_section') else '×œ×'}
  {'âœ…' if accuracy.get('complete_answer') else 'âŒ'} ×ª×•×›×Ÿ ××œ×: {'×›×Ÿ' if accuracy.get('complete_answer') else '×œ×'}
  {'âœ…' if accuracy.get('relevant_content') else 'âŒ'} ×¨×œ×•×•× ×˜×™: {'×›×Ÿ' if accuracy.get('relevant_content') else '×œ×'}
  ğŸ­ ×¡×•×’ ×©×’×™××”: {accuracy.get('error_type', '×œ×œ×')}

"""
        
        report += f"""
===============================================
ğŸ”§ ×”××œ×¦×•×ª ×œ×©×™×¤×•×¨:
===============================================

ğŸš¨ ×‘×¢×™×•×ª ×©×–×•×”×•:
"""
        
        # × ×™×ª×•×— ×‘×¢×™×•×ª
        wrong_section_count = sum(1 for r in self.test_results 
                                if r.get('accuracy_assessment', {}).get('error_type') == 'wrong_section')
        incomplete_count = sum(1 for r in self.test_results 
                             if r.get('accuracy_assessment', {}).get('error_type') == 'incomplete')
        
        if wrong_section_count > 0:
            report += f"1. ×‘×œ×‘×•×œ ×‘×™×Ÿ ×¡×¢×™×¤×™× ×“×•××™× ({wrong_section_count} ×©××œ×•×ª)\n"
        if incomplete_count > 0:
            report += f"2. ×ª×©×•×‘×•×ª ×—×œ×§×™×•×ª ({incomplete_count} ×©××œ×•×ª)\n"
        if stats.get('avg_response_time_ms', 0) > 2000:
            report += f"3. ×–××Ÿ ×ª×’×•×‘×” ××™×˜×™ ({stats.get('avg_response_time_ms', 0):.1f}ms ×××•×¦×¢)\n"
        
        report += f"""
ğŸ’¡ ×”×¦×¢×•×ª ×œ×©×™×¤×•×¨:
"""
        for i, rec in enumerate(recommendations, 1):
            report += f"{i}. {rec}\n"
        
        report += "\n===============================================\n"
        
        return report
    
    def create_chunks_analysis(self) -> str:
        """×™×¦×™×¨×ª × ×™×ª×•×— ××¤×•×¨×˜ ×©×œ ×¦'×× ×§×™×"""
        analysis = f"""===============================================
ğŸ” × ×™×ª×•×— ××¤×•×¨×˜ ×©×œ ×¦'×× ×§×™× - {self.timestamp}
===============================================

ğŸ“Š ×¡×˜×˜×™×¡×˜×™×§×•×ª ×›×œ×œ×™×•×ª:
----------------------------------------
"""
        
        all_chunks = []
        for result in self.test_results:
            if 'chunks_selected' in result:
                all_chunks.extend(result['chunks_selected'])
        
        if not all_chunks:
            return analysis + "âŒ ×œ× × ××¦××• ×¦'×× ×§×™× ×œ× ×™×ª×•×—\n"
        
        # ×¡×˜×˜×™×¡×˜×™×§×•×ª ×“××™×•×Ÿ
        similarity_scores = [chunk.get('similarity_score', 0) for chunk in all_chunks]
        avg_similarity = sum(similarity_scores) / len(similarity_scores) if similarity_scores else 0
        max_similarity = max(similarity_scores) if similarity_scores else 0
        min_similarity = min(similarity_scores) if similarity_scores else 0
        
        analysis += f"""
ğŸ”¸ ×¡×”"×› ×¦'×× ×§×™× ×©× ×‘×—×¨×•: {len(all_chunks)}
ğŸ”¸ ×¦×™×•×Ÿ ×“××™×•×Ÿ ×××•×¦×¢: {avg_similarity:.3f}
ğŸ”¸ ×¦×™×•×Ÿ ×“××™×•×Ÿ ××§×¡×™××œ×™: {max_similarity:.3f}
ğŸ”¸ ×¦×™×•×Ÿ ×“××™×•×Ÿ ××™× ×™××œ×™: {min_similarity:.3f}
ğŸ”¸ ×¦'×× ×§×™× ××¢×œ ×¡×£ ×”×“××™×•×Ÿ (0.65): {sum(1 for s in similarity_scores if s > 0.65)}

ğŸ“ˆ ×”×ª×¤×œ×’×•×ª ×¦×™×•× ×™ ×“××™×•×Ÿ:
----------------------------------------
"""
        
        # ×”×™×¡×˜×•×’×¨××” ×©×œ ×¦×™×•× ×™ ×“××™×•×Ÿ
        ranges = [(0, 0.3), (0.3, 0.5), (0.5, 0.7), (0.7, 0.85), (0.85, 1.0)]
        for low, high in ranges:
            count = sum(1 for s in similarity_scores if low <= s < high)
            percentage = (count / len(similarity_scores)) * 100 if similarity_scores else 0
            bar = "â–ˆ" * int(percentage / 5)  # ×‘×¨ ×’×¨×¤×™
            analysis += f"{low:.1f}-{high:.1f}: {count:3d} ({percentage:5.1f}%) {bar}\n"
        
        # × ×™×ª×•×— ××¡××›×™×
        doc_analysis = {}
        for chunk in all_chunks:
            doc_name = chunk.get('metadata', {}).get('document', '×œ× ×–×•×”×”')
            if doc_name not in doc_analysis:
                doc_analysis[doc_name] = 0
            doc_analysis[doc_name] += 1
        
        analysis += f"""

ğŸ“š ×”×ª×¤×œ×’×•×ª ×œ×¤×™ ××¡××›×™×:
----------------------------------------
"""
        for doc, count in sorted(doc_analysis.items(), key=lambda x: x[1], reverse=True):
            percentage = (count / len(all_chunks)) * 100
            analysis += f"ğŸ“„ {doc}: {count} ×¦'×× ×§×™× ({percentage:.1f}%)\n"
        
        # × ×™×ª×•×— ×¡×¢×™×¤×™× ×©×–×•×”×•
        section_analysis = {}
        for chunk in all_chunks:
            section = chunk.get('section_detected', '×œ× ×–×•×”×”')
            if section not in section_analysis:
                section_analysis[section] = 0
            section_analysis[section] += 1
        
        analysis += f"""

ğŸ·ï¸ ×¡×¢×™×¤×™× ×©×–×•×”×• ×”×›×™ ×”×¨×‘×”:
----------------------------------------
"""
        top_sections = sorted(section_analysis.items(), key=lambda x: x[1], reverse=True)[:10]
        for section, count in top_sections:
            analysis += f"ğŸ“‹ {section}: {count} ×¤×¢××™×\n"
        
        return analysis


async def main():
    """×¤×•× ×§×¦×™×” ×¨××©×™×ª"""
    print("ğŸš€ ××ª×—×™×œ ×‘×“×™×§×ª ××¢×¨×›×ª RAG...")
    print("=" * 50)
    
    try:
        tester = RAGTester()
        await tester.run_all_tests()
        
        print("\nğŸ“Š ×™×•×¦×¨ ×“×•×—×•×ª...")
        tester.save_detailed_report()
        
        # ×”×¦×’×ª ×¡×™×›×•× ××”×™×¨
        stats = tester.generate_summary_stats()
        print(f"""
âœ… ×‘×“×™×§×” ×”×•×©×œ××” ×‘×”×¦×œ×—×”!
ğŸ“ˆ ×ª×•×¦××•×ª:
   - ×©××œ×•×ª × ×‘×“×§×•: {stats.get('total_questions', 0)}
   - ×©×™×¢×•×¨ ×”×¦×œ×—×”: {stats.get('success_rate', 0):.1f}%
   - ×–××Ÿ ×××•×¦×¢: {stats.get('avg_response_time_ms', 0):.1f}ms
   
ğŸ“ ×”×“×•×—×•×ª × ×©××¨×• ×‘×ª×™×§×™×™×ª: RAG_test/results/
   - test_report_{tester.timestamp}.txt (×“×•×— ××¤×•×¨×˜)
   - rag_settings_{tester.timestamp}.json (×”×’×“×¨×•×ª)
   - chunks_analysis_{tester.timestamp}.txt (× ×™×ª×•×— ×¦'×× ×§×™×)
   - raw_results_{tester.timestamp}.json (× ×ª×•× ×™× ×’×•×œ××™×™×)
""")
        
        recommendations = tester.generate_recommendations(stats)
        if recommendations:
            print("ğŸ’¡ ×”××œ×¦×•×ª ×¢×™×§×¨×™×•×ª:")
            for rec in recommendations[:3]:  # ××¦×™×’ 3 ×¨××©×•× ×•×ª
                print(f"   {rec}")
        
    except Exception as e:
        logger.error(f"×©×’×™××” ×‘×‘×™×¦×•×¢ ×‘×“×™×§×”: {e}", exc_info=True)
        print(f"âŒ ×©×’×™××”: {e}")
        return 1
    
    return 0


if __name__ == "__main__":
    # ×”×¨×¦×ª ×”×‘×“×™×§×”
    exit_code = asyncio.run(main())
    sys.exit(exit_code) 