#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
×ž×¢×¨×›×ª ×‘×“×™×§×” ×ž×œ××” ×œRAG - ×ž×›×œ×œ×ª ××¤×§×”
=====================================

×¡×§×¨×™×¤×˜ ×–×” ×ž×¨×™×¥ ×‘×“×™×§×” ×ž×§×™×¤×” ×©×œ ×ž×¢×¨×›×ª ×”-RAG ×•×™×•×¦×¨ ×“×•×—×•×ª ×ž×¤×•×¨×˜×™×.
"""

import os
import sys
import json
import time
import asyncio
import logging
from datetime import datetime
from typing import Dict, List, Any, Optional
from pathlib import Path

# Add the backend directory to sys.path to allow importing from services
current_dir = Path(__file__).parent
backend_dir = current_dir.parent / "src" / "backend"
if str(backend_dir) not in sys.path:
    sys.path.insert(0, str(backend_dir))

try:
    from services.rag_service import RAGService
    from app.config.settings import settings
except ImportError as e:
    print(f"×©×’×™××” ×‘×™×™×‘×•× ×ž×•×“×•×œ×™×: {e}")
    print("×•×•×“× ×©××ª×” ×ž×¨×™×¥ ××ª ×”×¡×§×¨×™×¤×˜ ×ž×”×ª×™×§×™×™×” ×”×¨××©×™×ª ×©×œ ×”×¤×¨×•×™×§×˜")
    sys.exit(1)

# ×”×’×“×¨×ª ×œ×•×’×™× ×’
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('results/test_debug.log', encoding='utf-8')
    ]
)

logger = logging.getLogger(__name__)

class RAGTester:
    """×ž×—×œ×§×” ×œ×‘×“×™×§×ª ×ž×¢×¨×›×ª RAG"""
    
    def __init__(self):
        self.rag_service = None
        self.test_results = []
        self.start_time = None
        self.end_time = None
        self.timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # ×˜×¢×™× ×ª ×©××œ×•×ª ×‘×“×™×§×”
        with open('test_questions.json', 'r', encoding='utf-8') as f:
            self.questions = json.load(f)['questions']
    
    async def initialize_services(self):
        """××ª×—×•×œ ×©×™×¨×•×ª×™×"""
        try:
            logger.info("×ž××ª×—×œ ×©×™×¨×•×ª×™ RAG...")
            # ðŸŽ¯ ×©×™×ž×•×© ×‘×¤×¨×•×¤×™×œ ×ž×¨×›×–×™ - ×œ×œ× hard-coding!
            self.rag_service = RAGService()  # ×™×˜×¢×Ÿ ××ª ×”×¤×¨×•×¤×™×œ ×”×ž×¨×›×–×™ ××•×˜×•×ž×˜×™×ª
            logger.info("×©×™×¨×•×ª×™× ××•×ª×—×œ×• ×‘×”×¦×œ×—×”")
        except Exception as e:
            logger.error(f"×©×’×™××” ×‘××ª×—×•×œ ×©×™×¨×•×ª×™×: {e}")
            raise
    
    def extract_current_settings(self) -> Dict[str, Any]:
        """×—×™×œ×•×¥ ×”×’×“×¨×•×ª RAG × ×•×›×—×™×•×ª"""
        return {
            "timestamp": self.timestamp,
            "rag_settings": {
                "max_context_tokens": getattr(self.rag_service, 'max_context_tokens', 'N/A'),
                "similarity_threshold": getattr(self.rag_service, 'similarity_threshold', 'N/A'),
                "max_chunks": getattr(self.rag_service, 'max_chunks', 'N/A'),
                "embedding_model": "models/embedding-001",
                "llm_model": getattr(self.rag_service, 'model', {}).model_name if hasattr(self.rag_service, 'model') else 'N/A'
            },
            "chat_settings": {
                "gemini_model": settings.GEMINI_MODEL_NAME,
                "temperature": settings.GEMINI_TEMPERATURE,
                "max_tokens": settings.GEMINI_MAX_TOKENS,
                "history_window": settings.LANGCHAIN_HISTORY_K
            },
            "system_info": {
                "python_version": sys.version,
                "working_directory": os.getcwd()
            }
        }
    
    async def test_single_question(self, question_data: Dict[str, Any]) -> Dict[str, Any]:
        """×‘×“×™×§×ª ×©××œ×” ×™×—×™×“×”"""
        logger.info(f"×‘×•×“×§ ×©××œ×” #{question_data['id']}: {question_data['question']}")
        
        start_time = time.time()
        
        try:
            # ×‘×™×¦×•×¢ ×”×—×™×¤×•×© ×‘××ž×¦×¢×•×ª RAG service
            rag_result = await self.rag_service.generate_answer(
                query=question_data['question'],
                search_method="hybrid"
            )
            
            response_time = (time.time() - start_time) * 1000  # ×‘×ž×™×œ×™×©× ×™×•×ª
            
            # × ×™×ª×•×— ×”×ª×•×¦××•×ª
            chunks_info = []
            if 'chunks_selected' in rag_result:
                for i, chunk in enumerate(rag_result['chunks_selected']):
                    chunk_info = {
                        "chunk_id": chunk.get('chunk_id', f'chunk_{i}'),
                        "similarity_score": chunk.get('similarity_score', chunk.get('combined_score', 0)),
                        "section_detected": chunk.get('section', '×œ× ×–×•×”×”'),
                        "content_preview": chunk.get('chunk_text', '')[:100] + "..." if chunk.get('chunk_text') else '',
                        "metadata": {
                            "document": chunk.get('document_name', '×œ× ×–×•×”×”'),
                            "page": chunk.get('page_number', '×œ× ×–×•×”×”'),
                            "chunk_header": chunk.get('chunk_header', '×œ× ×–×•×”×”')
                        }
                    }
                    chunks_info.append(chunk_info)
            
            # ×”×¢×¨×›×ª ×“×™×•×§
            accuracy = self.assess_accuracy(question_data, rag_result, chunks_info)
            
            result = {
                "question_id": question_data['id'],
                "category": question_data['category'],
                "question": question_data['question'],
                "expected_section": question_data['expected_section'],
                "expected_content": question_data['expected_content'],
                "difficulty": question_data['difficulty'],
                "timestamp": datetime.now().isoformat(),
                "response_time_ms": round(response_time, 2),
                "answer": rag_result.get('answer', '×œ× ×”×ª×§×‘×œ×” ×ª×©×•×‘×”'),
                "chunks_selected": chunks_info,
                "total_chunks_retrieved": len(chunks_info),
                "sources_count": len(rag_result.get('sources', [])),
                "context_tokens_estimated": self.estimate_tokens(rag_result.get('answer', '')),
                "accuracy_assessment": accuracy,
                "raw_rag_result": rag_result  # ×œ×¦×•×¨×š ×“×™×‘×•×’
            }
            
            return result
            
        except Exception as e:
            logger.error(f"×©×’×™××” ×‘×‘×“×™×§×ª ×©××œ×” #{question_data['id']}: {e}")
            return {
                "question_id": question_data['id'],
                "category": question_data['category'],
                "question": question_data['question'],
                "error": str(e),
                "timestamp": datetime.now().isoformat(),
                "response_time_ms": (time.time() - start_time) * 1000
            }
    
    def assess_accuracy(self, question_data: Dict[str, Any], rag_result: Dict[str, Any], chunks_info: List[Dict]) -> Dict[str, Any]:
        """×”×¢×¨×›×ª ×“×™×•×§ ×”×ª×©×•×‘×”"""
        answer = rag_result.get('answer', '').lower()
        expected_section = question_data['expected_section'].lower()
        
        # ×‘×“×™×§×” ×× ×”×¡×¢×™×£ ×”× ×›×•×Ÿ × ×ž×¦×
        correct_section = False
        if expected_section != 'multiple' and expected_section != 'none':
            correct_section = expected_section in answer
            # ×‘×“×™×§×” ×’× ×‘×¦'×× ×§×™×
            if not correct_section:
                for chunk in chunks_info:
                    if expected_section in chunk['section_detected'].lower():
                        correct_section = True
                        break
        elif expected_section == 'multiple':
            correct_section = len(chunks_info) > 0  # ×× ×ž×¦× ×ž×©×”×• ×¨×œ×•×•× ×˜×™
        elif expected_section == 'none':
            correct_section = len(chunks_info) == 0 or "×œ× × ×ž×¦×" in answer or "××™×Ÿ ×ž×™×“×¢" in answer
        
        # ×‘×“×™×§×ª ×©×œ×ž×•×ª ×”×ª×©×•×‘×”
        complete_answer = len(answer) > 50 and "×œ× × ×ž×¦×" not in answer
        
        # ×‘×“×™×§×ª ×¨×œ×•×•× ×˜×™×•×ª
        relevant_content = len(chunks_info) > 0 and any(
            chunk['similarity_score'] > 0.6 for chunk in chunks_info
        )
        
        # ×§×‘×™×¢×ª ×¡×•×’ ×©×’×™××”
        error_type = "none"
        if not correct_section:
            error_type = "wrong_section"
        elif not complete_answer:
            error_type = "incomplete"
        elif not relevant_content:
            error_type = "irrelevant"
        
        return {
            "correct_section": correct_section,
            "complete_answer": complete_answer,
            "relevant_content": relevant_content,
            "error_type": error_type,
            "overall_success": correct_section and complete_answer and relevant_content
        }
    
    def estimate_tokens(self, text: str) -> int:
        """×”×¢×¨×›×ª ×ž×¡×¤×¨ ×˜×•×§× ×™×"""
        return int(len(text.split()) * 1.3)  # ×”×¢×¨×›×” ×’×¡×”
    
    async def run_all_tests(self):
        """×”×¨×¦×ª ×›×œ ×”×‘×“×™×§×•×ª"""
        logger.info("×ž×ª×—×™×œ ×‘×“×™×§×•×ª RAG...")
        self.start_time = datetime.now()
        
        await self.initialize_services()
        
        for question in self.questions:
            result = await self.test_single_question(question)
            self.test_results.append(result)
            
            # ×”×ž×ª× ×” ×§×¦×¨×” ×‘×™×Ÿ ×©××œ×•×ª
            await asyncio.sleep(0.5)
        
        self.end_time = datetime.now()
        logger.info("×‘×“×™×§×•×ª ×”×•×©×œ×ž×•!")
    
    def generate_summary_stats(self) -> Dict[str, Any]:
        """×™×¦×™×¨×ª ×¡×˜×˜×™×¡×˜×™×§×•×ª ×¡×™×›×•×"""
        total_questions = len(self.test_results)
        successful_tests = [r for r in self.test_results if 'error' not in r]
        
        if not successful_tests:
            return {"error": "×œ× ×”×¦×œ×™×—×” ××£ ×‘×“×™×§×”"}
        
        # ×¡×˜×˜×™×¡×˜×™×§×•×ª ×›×œ×œ×™×•×ª
        correct_answers = sum(1 for r in successful_tests 
                            if r.get('accuracy_assessment', {}).get('overall_success', False))
        partial_answers = sum(1 for r in successful_tests 
                            if r.get('accuracy_assessment', {}).get('correct_section', False) 
                            and not r.get('accuracy_assessment', {}).get('overall_success', False))
        wrong_answers = total_questions - correct_answers - partial_answers
        
        # ×–×ž×Ÿ ×ª×’×•×‘×” ×ž×ž×•×¦×¢
        avg_response_time = sum(r.get('response_time_ms', 0) for r in successful_tests) / len(successful_tests)
        
        # ×¡×˜×˜×™×¡×˜×™×§×•×ª ×œ×¤×™ ×§×˜×’×•×¨×™×”
        categories_stats = {}
        for result in successful_tests:
            category = result.get('category', '×œ× ×–×•×”×”')
            if category not in categories_stats:
                categories_stats[category] = {'total': 0, 'correct': 0}
            categories_stats[category]['total'] += 1
            if result.get('accuracy_assessment', {}).get('overall_success', False):
                categories_stats[category]['correct'] += 1
        
        return {
            "total_questions": total_questions,
            "correct_answers": correct_answers,
            "partial_answers": partial_answers,
            "wrong_answers": wrong_answers,
            "success_rate": (correct_answers / total_questions) * 100,
            "partial_rate": (partial_answers / total_questions) * 100,
            "error_rate": (wrong_answers / total_questions) * 100,
            "avg_response_time_ms": round(avg_response_time, 2),
            "categories_stats": categories_stats,
            "test_duration_seconds": (self.end_time - self.start_time).total_seconds()
        }
    
    def generate_recommendations(self, stats: Dict[str, Any]) -> List[str]:
        """×™×¦×™×¨×ª ×”×ž×œ×¦×•×ª ×œ×©×™×¤×•×¨"""
        recommendations = []
        
        success_rate = stats.get('success_rate', 0)
        avg_response_time = stats.get('avg_response_time_ms', 0)
        
        # ×”×ž×œ×¦×•×ª ×¢×œ ×¡×ž×š ×©×™×¢×•×¨ ×”×¦×œ×—×”
        if success_rate < 70:
            recommendations.append("ðŸš¨ ×©×™×¢×•×¨ ×”×¦×œ×—×” × ×ž×•×š - ×”× ×ž×š ××ª ×¡×£ ×”×“×ž×™×•×Ÿ ×œ-0.5")
            recommendations.append("ðŸ”§ ×”×’×“×œ ××ª ×ž×¡×¤×¨ ×”×¦'×× ×§×™× ×”× ×©×œ×¤×™× ×œ-12")
        elif success_rate < 85:
            recommendations.append("âš ï¸ ×©×™×¢×•×¨ ×”×¦×œ×—×” ×‘×™× ×•× ×™ - ×©×§×•×œ ×œ×”×’×“×™×œ ××ª ×ž×¡×¤×¨ ×”×¦'×× ×§×™× ×‘×§×•× ×˜×§×¡×˜")
        
        # ×”×ž×œ×¦×•×ª ×¢×œ ×¡×ž×š ×–×ž×Ÿ ×ª×’×•×‘×”
        if avg_response_time > 3000:
            recommendations.append("â±ï¸ ×–×ž×Ÿ ×ª×’×•×‘×” ××™×˜×™ - ×©×§×•×œ ×œ×”×§×˜×™×Ÿ ××ª ×ž×¡×¤×¨ ×”×¦'×× ×§×™×")
            recommendations.append("ðŸš€ ×©×§×•×œ ××•×¤×˜×™×ž×™×–×¦×™×” ×©×œ ×—×™×¤×•×© ×‘×ž×¡×“ ×”× ×ª×•× ×™×")
        
        # ×”×ž×œ×¦×•×ª ×¡×¤×¦×™×¤×™×•×ª ×œ×§×˜×’×•×¨×™×•×ª
        categories = stats.get('categories_stats', {})
        for category, cat_stats in categories.items():
            success_rate_cat = (cat_stats['correct'] / cat_stats['total']) * 100 if cat_stats['total'] > 0 else 0
            if success_rate_cat < 60:
                recommendations.append(f"ðŸ“š ×§×˜×’×•×¨×™×” '{category}': ×©×™×¢×•×¨ ×”×¦×œ×—×” × ×ž×•×š ({success_rate_cat:.1f}%) - ×©×¤×¨ ×–×™×”×•×™ ×ž×™×œ×•×ª ×ž×¤×ª×—")
        
        # ×‘×“×™×§×” ×œ×’×‘×™ ×©××œ×•×ª ×ž×œ×›×•×“×ª
        trap_questions = [r for r in self.test_results if r.get('difficulty') == 'trap']
        trap_success = sum(1 for r in trap_questions if '×œ× × ×ž×¦×' in r.get('answer', '') or '××™×Ÿ ×ž×™×“×¢' in r.get('answer', ''))
        if len(trap_questions) > 0 and (trap_success / len(trap_questions)) < 0.5:
            recommendations.append("ðŸª¤ ×‘×¢×™×” ×‘×–×™×”×•×™ ×©××œ×•×ª ×ž×œ×›×•×“×ª - ×©×¤×¨ ×”× ×“×œ×™× ×’ ×©×œ ×ª×©×•×‘×•×ª '×œ× × ×ž×¦×'")
        
        if not recommendations:
            recommendations.append("âœ… ×ž×¢×¨×›×ª ×”-RAG ×¢×•×‘×“×ª ×‘×¦×•×¨×” ×ž×¦×•×™× ×ª!")
        
        return recommendations
    
    def save_detailed_report(self):
        """×©×ž×™×¨×ª ×“×•×— ×ž×¤×•×¨×˜"""
        settings_data = self.extract_current_settings()
        stats = self.generate_summary_stats()
        recommendations = self.generate_recommendations(stats)
        
        # ×©×ž×™×¨×ª ×”×’×“×¨×•×ª ×œ×ž×•×‘×Ÿ JSON
        with open(f'results/rag_settings_{self.timestamp}.json', 'w', encoding='utf-8') as f:
            json.dump(settings_data, f, ensure_ascii=False, indent=2)
        
        # ×™×¦×™×¨×ª ×“×•×— ×˜×§×¡×˜ ×ž×¤×•×¨×˜
        report_content = self.create_detailed_text_report(stats, recommendations)
        with open(f'results/test_report_{self.timestamp}.txt', 'w', encoding='utf-8') as f:
            f.write(report_content)
        
        # ×©×ž×™×¨×ª × ×™×ª×•×— ×¦'×× ×§×™×
        chunks_analysis = self.create_chunks_analysis()
        with open(f'results/chunks_analysis_{self.timestamp}.txt', 'w', encoding='utf-8') as f:
            f.write(chunks_analysis)
        
        # ×©×ž×™×¨×ª × ×ª×•× ×™× ×’×•×œ×ž×™×™× JSON
        with open(f'results/raw_results_{self.timestamp}.json', 'w', encoding='utf-8') as f:
            json.dump(self.test_results, f, ensure_ascii=False, indent=2)
        
        logger.info(f"×“×•×—×•×ª × ×©×ž×¨×• ×‘×ª×™×§×™×™×ª results/ ×¢× ×—×•×ª×ž×ª ×–×ž×Ÿ {self.timestamp}")
    
    def create_detailed_text_report(self, stats: Dict[str, Any], recommendations: List[str]) -> str:
        """×™×¦×™×¨×ª ×“×•×— ×˜×§×¡×˜ ×ž×¤×•×¨×˜"""
        
        report = f"""===============================================
ðŸ§ª ×“×•×— ×‘×“×™×§×ª ×ž×¢×¨×›×ª RAG - ×ž×›×œ×œ×ª ××¤×§×”
===============================================
ðŸ“… ×ª××¨×™×š: {self.start_time.strftime('%Y-%m-%d %H:%M:%S')}
â±ï¸ ×ž×©×š ×‘×“×™×§×”: {stats.get('test_duration_seconds', 0):.1f} ×©× ×™×•×ª
ðŸ”§ ×’×¨×¡×ª ×ž×¢×¨×›×ª: v2.1.3

ðŸ“Š ×”×’×“×¨×•×ª RAG × ×•×›×—×™×•×ª:
----------------------------------------
ðŸ”¸ ×ž×§×¡ ×˜×•×§× ×™× ×‘×§×•× ×˜×§×¡×˜: {self.rag_service.context_config.MAX_CONTEXT_TOKENS if self.rag_service else 'N/A'}
ðŸ”¸ ×¡×£ ×“×ž×™×•×Ÿ: {self.rag_service.search_config.SIMILARITY_THRESHOLD if self.rag_service else 'N/A'}
ðŸ”¸ ×ž×§×¡ ×¦'×× ×§×™×: {self.rag_service.search_config.MAX_CHUNKS_RETRIEVED if self.rag_service else 'N/A'}
ðŸ”¸ ×ž×•×“×œ embedding: {self.rag_service.embedding_config.MODEL_NAME if self.rag_service else 'models/embedding-001'}
ðŸ”¸ ×ž×•×“×œ LLM: {self.rag_service.llm_config.MODEL_NAME if self.rag_service else 'N/A'}
ðŸ”¸ ×˜×ž×¤×¨×˜×•×¨×”: {self.rag_service.llm_config.TEMPERATURE if self.rag_service else 'N/A'}
ðŸ”¸ ×ž×§×¡ ×˜×•×§× ×™×: {self.rag_service.llm_config.MAX_OUTPUT_TOKENS if self.rag_service else 'N/A'}

ðŸ“ˆ ×¡×™×›×•× ×ª×•×¦××•×ª:
----------------------------------------
âœ… ×ª×©×•×‘×•×ª × ×›×•× ×•×ª: {stats.get('correct_answers', 0)}/{stats.get('total_questions', 0)} ({stats.get('success_rate', 0):.1f}%)
âš ï¸ ×ª×©×•×‘×•×ª ×—×œ×§×™×•×ª: {stats.get('partial_answers', 0)}/{stats.get('total_questions', 0)} ({stats.get('partial_rate', 0):.1f}%)
âŒ ×ª×©×•×‘×•×ª ×©×’×•×™×•×ª: {stats.get('wrong_answers', 0)}/{stats.get('total_questions', 0)} ({stats.get('error_rate', 0):.1f}%)
â±ï¸ ×–×ž×Ÿ ×ª×’×•×‘×” ×ž×ž×•×¦×¢: {stats.get('avg_response_time_ms', 0):.1f} ×ž×™×œ×™×©× ×™×•×ª

ðŸŽ¯ ×“×™×•×§ ×œ×¤×™ ×§×˜×’×•×¨×™×•×ª:
----------------------------------------"""
        
        for category, cat_stats in stats.get('categories_stats', {}).items():
            success_rate = (cat_stats['correct'] / cat_stats['total']) * 100 if cat_stats['total'] > 0 else 0
            report += f"\nðŸ”¹ {category}: {cat_stats['correct']}/{cat_stats['total']} ({success_rate:.1f}%)"
        
        report += f"""

===============================================
ðŸ“‹ ×ª×•×¦××•×ª ×ž×¤×•×¨×˜×•×ª ×œ×›×œ ×©××œ×”:
===============================================
"""
        
        for result in self.test_results:
            if 'error' in result:
                report += f"""
âŒ ×©××œ×” #{result['question_id']}: "{result['question']}"
----------------------------------------
âš ï¸ ×©×’×™××”: {result['error']}
â±ï¸ ×–×ž×Ÿ ×ª×’×•×‘×”: {result.get('response_time_ms', 0):.1f} ×ž×™×œ×™×©× ×™×•×ª

"""
                continue
            
            accuracy = result.get('accuracy_assessment', {})
            chunks = result.get('chunks_selected', [])
            
            # ××™×™×§×•×Ÿ ×œ×¤×™ ×”×¦×œ×—×”
            if accuracy.get('overall_success', False):
                icon = "âœ…"
            elif accuracy.get('correct_section', False):
                icon = "âš ï¸"
            else:
                icon = "âŒ"
            
            report += f"""
{icon} ×©××œ×” #{result['question_id']}: "{result['question']}"
----------------------------------------
ðŸ“‚ ×§×˜×’×•×¨×™×”: {result['category']}
ðŸŽ¯ ×¨×ž×ª ×§×•×©×™: {result['difficulty']}
â±ï¸ ×–×ž×Ÿ ×ª×’×•×‘×”: {result['response_time_ms']:.1f} ×ž×™×œ×™×©× ×™×•×ª
ðŸ“ ×¡×¢×™×£ ×ž×¦×•×¤×”: {result['expected_section']}

ðŸ§© ×¦'×× ×§×™× ×©× ×‘×—×¨×• ({len(chunks)} ×¡×”"×›):"""
            
            for i, chunk in enumerate(chunks[:5]):  # ×ž×¦×™×’ ×¨×§ 5 ×¨××©×•× ×™×
                report += f"""
  ðŸ“„ chunk_{i+1} (×“×ž×™×•×Ÿ: {chunk.get('similarity_score', 0):.2f}) - {chunk.get('section_detected', '×œ× ×–×•×”×”')}"""
            
            if len(chunks) > 5:
                report += f"\n  ... ×•×¢×•×“ {len(chunks) - 5} ×¦'×× ×§×™×"
            
            # ×ª×•×¦××•×ª ×”×¢×¨×›×”
            report += f"""

ðŸ’¬ ×”×ª×©×•×‘×”:
"{result['answer'][:200]}{'...' if len(result['answer']) > 200 else ''}"

âœ… ×”×¢×¨×›×ª ×“×™×•×§:
  {'âœ…' if accuracy.get('correct_section') else 'âŒ'} ×¡×¢×™×£ × ×›×•×Ÿ: {'×›×Ÿ' if accuracy.get('correct_section') else '×œ×'}
  {'âœ…' if accuracy.get('complete_answer') else 'âŒ'} ×ª×•×›×Ÿ ×ž×œ×: {'×›×Ÿ' if accuracy.get('complete_answer') else '×œ×'}
  {'âœ…' if accuracy.get('relevant_content') else 'âŒ'} ×¨×œ×•×•× ×˜×™: {'×›×Ÿ' if accuracy.get('relevant_content') else '×œ×'}
  ðŸŽ­ ×¡×•×’ ×©×’×™××”: {accuracy.get('error_type', '×œ×œ×')}

"""
        
        report += f"""
===============================================
ðŸ”§ ×”×ž×œ×¦×•×ª ×œ×©×™×¤×•×¨:
===============================================

ðŸš¨ ×‘×¢×™×•×ª ×©×–×•×”×•:
"""
        
        # × ×™×ª×•×— ×‘×¢×™×•×ª
        wrong_section_count = sum(1 for r in self.test_results 
                                if r.get('accuracy_assessment', {}).get('error_type') == 'wrong_section')
        incomplete_count = sum(1 for r in self.test_results 
                             if r.get('accuracy_assessment', {}).get('error_type') == 'incomplete')
        
        if wrong_section_count > 0:
            report += f"1. ×‘×œ×‘×•×œ ×‘×™×Ÿ ×¡×¢×™×¤×™× ×“×•×ž×™× ({wrong_section_count} ×©××œ×•×ª)\n"
        if incomplete_count > 0:
            report += f"2. ×ª×©×•×‘×•×ª ×—×œ×§×™×•×ª ({incomplete_count} ×©××œ×•×ª)\n"
        if stats.get('avg_response_time_ms', 0) > 2000:
            report += f"3. ×–×ž×Ÿ ×ª×’×•×‘×” ××™×˜×™ ({stats.get('avg_response_time_ms', 0):.1f}ms ×ž×ž×•×¦×¢)\n"
        
        report += f"""
ðŸ’¡ ×”×¦×¢×•×ª ×œ×©×™×¤×•×¨:
"""
        for i, rec in enumerate(recommendations, 1):
            report += f"{i}. {rec}\n"
        
        report += "\n===============================================\n"
        
        return report
    
    def create_chunks_analysis(self) -> str:
        """×™×¦×™×¨×ª × ×™×ª×•×— ×ž×¤×•×¨×˜ ×©×œ ×¦'×× ×§×™×"""
        analysis = f"""===============================================
ðŸ” × ×™×ª×•×— ×ž×¤×•×¨×˜ ×©×œ ×¦'×× ×§×™× - {self.timestamp}
===============================================

ðŸ“Š ×¡×˜×˜×™×¡×˜×™×§×•×ª ×›×œ×œ×™×•×ª:
----------------------------------------
"""
        
        all_chunks = []
        for result in self.test_results:
            if 'chunks_selected' in result:
                all_chunks.extend(result['chunks_selected'])
        
        if not all_chunks:
            return analysis + "âŒ ×œ× × ×ž×¦××• ×¦'×× ×§×™× ×œ× ×™×ª×•×—\n"
        
        # ×¡×˜×˜×™×¡×˜×™×§×•×ª ×“×ž×™×•×Ÿ
        similarity_scores = [chunk.get('similarity_score', 0) for chunk in all_chunks]
        avg_similarity = sum(similarity_scores) / len(similarity_scores) if similarity_scores else 0
        max_similarity = max(similarity_scores) if similarity_scores else 0
        min_similarity = min(similarity_scores) if similarity_scores else 0
        
        analysis += f"""
ðŸ”¸ ×¡×”"×› ×¦'×× ×§×™× ×©× ×‘×—×¨×•: {len(all_chunks)}
ðŸ”¸ ×¦×™×•×Ÿ ×“×ž×™×•×Ÿ ×ž×ž×•×¦×¢: {avg_similarity:.3f}
ðŸ”¸ ×¦×™×•×Ÿ ×“×ž×™×•×Ÿ ×ž×§×¡×™×ž×œ×™: {max_similarity:.3f}
ðŸ”¸ ×¦×™×•×Ÿ ×“×ž×™×•×Ÿ ×ž×™× ×™×ž×œ×™: {min_similarity:.3f}
ðŸ”¸ ×¦'×× ×§×™× ×ž×¢×œ ×¡×£ ×”×“×ž×™×•×Ÿ (0.65): {sum(1 for s in similarity_scores if s > 0.65)}

ðŸ“ˆ ×”×ª×¤×œ×’×•×ª ×¦×™×•× ×™ ×“×ž×™×•×Ÿ:
----------------------------------------
"""
        
        # ×”×™×¡×˜×•×’×¨×ž×” ×©×œ ×¦×™×•× ×™ ×“×ž×™×•×Ÿ
        ranges = [(0, 0.3), (0.3, 0.5), (0.5, 0.7), (0.7, 0.85), (0.85, 1.0)]
        for low, high in ranges:
            count = sum(1 for s in similarity_scores if low <= s < high)
            percentage = (count / len(similarity_scores)) * 100 if similarity_scores else 0
            bar = "â–ˆ" * int(percentage / 5)  # ×‘×¨ ×’×¨×¤×™
            analysis += f"{low:.1f}-{high:.1f}: {count:3d} ({percentage:5.1f}%) {bar}\n"
        
        # × ×™×ª×•×— ×ž×¡×ž×›×™×
        doc_analysis = {}
        for chunk in all_chunks:
            doc_name = chunk.get('metadata', {}).get('document', '×œ× ×–×•×”×”')
            if doc_name not in doc_analysis:
                doc_analysis[doc_name] = 0
            doc_analysis[doc_name] += 1
        
        analysis += f"""

ðŸ“š ×”×ª×¤×œ×’×•×ª ×œ×¤×™ ×ž×¡×ž×›×™×:
----------------------------------------
"""
        for doc, count in sorted(doc_analysis.items(), key=lambda x: x[1], reverse=True):
            percentage = (count / len(all_chunks)) * 100
            analysis += f"ðŸ“„ {doc}: {count} ×¦'×× ×§×™× ({percentage:.1f}%)\n"
        
        # × ×™×ª×•×— ×¡×¢×™×¤×™× ×©×–×•×”×•
        section_analysis = {}
        for chunk in all_chunks:
            section = chunk.get('section_detected', '×œ× ×–×•×”×”')
            if section not in section_analysis:
                section_analysis[section] = 0
            section_analysis[section] += 1
        
        analysis += f"""

ðŸ·ï¸ ×¡×¢×™×¤×™× ×©×–×•×”×• ×”×›×™ ×”×¨×‘×”:
----------------------------------------
"""
        top_sections = sorted(section_analysis.items(), key=lambda x: x[1], reverse=True)[:10]
        for section, count in top_sections:
            analysis += f"ðŸ“‹ {section}: {count} ×¤×¢×ž×™×\n"
        
        return analysis


async def main():
    """×¤×•× ×§×¦×™×” ×¨××©×™×ª"""
    print("ðŸš€ ×ž×ª×—×™×œ ×‘×“×™×§×ª ×ž×¢×¨×›×ª RAG...")
    print("=" * 50)
    
    try:
        tester = RAGTester()
        await tester.run_all_tests()
        
        print("\nðŸ“Š ×™×•×¦×¨ ×“×•×—×•×ª...")
        tester.save_detailed_report()
        
        # ×”×¦×’×ª ×¡×™×›×•× ×ž×”×™×¨
        stats = tester.generate_summary_stats()
        print(f"""
âœ… ×‘×“×™×§×” ×”×•×©×œ×ž×” ×‘×”×¦×œ×—×”!
ðŸ“ˆ ×ª×•×¦××•×ª:
   - ×©××œ×•×ª × ×‘×“×§×•: {stats.get('total_questions', 0)}
   - ×©×™×¢×•×¨ ×”×¦×œ×—×”: {stats.get('success_rate', 0):.1f}%
   - ×–×ž×Ÿ ×ž×ž×•×¦×¢: {stats.get('avg_response_time_ms', 0):.1f}ms
   
ðŸ“ ×”×“×•×—×•×ª × ×©×ž×¨×• ×‘×ª×™×§×™×™×ª: RAG_test/results/
   - test_report_{tester.timestamp}.txt (×“×•×— ×ž×¤×•×¨×˜)
   - rag_settings_{tester.timestamp}.json (×”×’×“×¨×•×ª)
   - chunks_analysis_{tester.timestamp}.txt (× ×™×ª×•×— ×¦'×× ×§×™×)
   - raw_results_{tester.timestamp}.json (× ×ª×•× ×™× ×’×•×œ×ž×™×™×)
""")
        
        recommendations = tester.generate_recommendations(stats)
        if recommendations:
            print("ðŸ’¡ ×”×ž×œ×¦×•×ª ×¢×™×§×¨×™×•×ª:")
            for rec in recommendations[:3]:  # ×ž×¦×™×’ 3 ×¨××©×•× ×•×ª
                print(f"   {rec}")
        
    except Exception as e:
        logger.error(f"×©×’×™××” ×‘×‘×™×¦×•×¢ ×‘×“×™×§×”: {e}", exc_info=True)
        print(f"âŒ ×©×’×™××”: {e}")
        return 1
    
    return 0


if __name__ == "__main__":
    # ×”×¨×¦×ª ×”×‘×“×™×§×”
    exit_code = asyncio.run(main())
    sys.exit(exit_code) 